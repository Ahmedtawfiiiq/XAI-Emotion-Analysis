{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install gdown","metadata":{"id":"FtXnDFfR4_2b","outputId":"4e6de28f-8ba8-4e49-b0c3-21acba14110f","execution":{"iopub.status.busy":"2023-08-12T12:58:54.554347Z","iopub.execute_input":"2023-08-12T12:58:54.554611Z","iopub.status.idle":"2023-08-12T12:59:10.032747Z","shell.execute_reply.started":"2023-08-12T12:58:54.554586Z","shell.execute_reply":"2023-08-12T12:59:10.031490Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.65.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"train = '1HqceFWkRXwEqgPcuAtACFVvHhKO_TGG6'\nval = '1XEsLOUFJTnCGcitk4IUS23H6IlzCzwqZ'\ntest = '1Lu5ItQvj2iGRqMXJ-bovQkys0eilR9HZ'\n\ntrain_embeddings_per_word = '1-0Bb3pLy_EhEggA-VsOh8TIS92VbmmxV'\nval_embeddings_per_word = '1-0WpebJIz9q2PZ_Baf51ZUsiBx9pWVJP'\ntest_embeddings_per_word = '1pi6DGhZ7AoGzC3cqP-ET5Qvkc3HD33bo'\n\ntrain_embeddings_per_sentence = '1-260zeDhoDdxQ3McfR7Hr4c6mfaLFBpa'\nval_embeddings_per_sentence = '1-2EN_l5NcdgJZ740Szt4g6RcIZ9GX_D2'\ntest_embeddings_per_sentence = '1gNKahNHussBAV-6mFyC66AxPTA0YhQAG'","metadata":{"execution":{"iopub.status.busy":"2023-08-12T12:59:10.035278Z","iopub.execute_input":"2023-08-12T12:59:10.035668Z","iopub.status.idle":"2023-08-12T12:59:10.041979Z","shell.execute_reply.started":"2023-08-12T12:59:10.035631Z","shell.execute_reply":"2023-08-12T12:59:10.041045Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!gdown {train}\n!gdown {val}\n!gdown {test}\n\n!gdown {train_embeddings_per_word}\n!gdown {val_embeddings_per_word}\n!gdown {test_embeddings_per_word}","metadata":{"execution":{"iopub.status.busy":"2023-08-12T12:59:10.043373Z","iopub.execute_input":"2023-08-12T12:59:10.044325Z","iopub.status.idle":"2023-08-12T12:59:31.112966Z","shell.execute_reply.started":"2023-08-12T12:59:10.044282Z","shell.execute_reply":"2023-08-12T12:59:31.111404Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1HqceFWkRXwEqgPcuAtACFVvHhKO_TGG6\nTo: /kaggle/working/train_final.pkl\n100%|███████████████████████████████████████| 3.47M/3.47M [00:00<00:00, 191MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1XEsLOUFJTnCGcitk4IUS23H6IlzCzwqZ\nTo: /kaggle/working/val_final.pkl\n100%|█████████████████████████████████████████| 743k/743k [00:00<00:00, 111MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1Lu5ItQvj2iGRqMXJ-bovQkys0eilR9HZ\nTo: /kaggle/working/test_final.pkl\n100%|█████████████████████████████████████████| 737k/737k [00:00<00:00, 125MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1-0Bb3pLy_EhEggA-VsOh8TIS92VbmmxV\nFrom (redirected): https://drive.google.com/uc?id=1-0Bb3pLy_EhEggA-VsOh8TIS92VbmmxV&confirm=t&uuid=816eabb8-6f49-4373-b569-a1dedc3a7ff5\nTo: /kaggle/working/train_embeddings_per_word.pkl\n100%|███████████████████████████████████████| 1.08G/1.08G [00:03<00:00, 292MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1-0WpebJIz9q2PZ_Baf51ZUsiBx9pWVJP\nFrom (redirected): https://drive.google.com/uc?id=1-0WpebJIz9q2PZ_Baf51ZUsiBx9pWVJP&confirm=t&uuid=532ca7ed-d920-47ae-8e9a-175d489508ba\nTo: /kaggle/working/val_embeddings_per_word.pkl\n100%|█████████████████████████████████████████| 232M/232M [00:00<00:00, 271MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1pi6DGhZ7AoGzC3cqP-ET5Qvkc3HD33bo\nFrom (redirected): https://drive.google.com/uc?id=1pi6DGhZ7AoGzC3cqP-ET5Qvkc3HD33bo&confirm=t&uuid=43c64a88-b03b-41da-a5b9-b3df8f036bb5\nTo: /kaggle/working/test_embeddings_per_word.pkl\n100%|█████████████████████████████████████████| 232M/232M [00:01<00:00, 185MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nimport string\nimport re\nimport pickle\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.isri import ISRIStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import confusion_matrix,accuracy_score, classification_report\nfrom sklearn.svm import SVC\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.layers import MaxPooling1D\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import backend as K\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nimport seaborn as sns\nimport torch\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing import sequence\nfrom collections import OrderedDict\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"id":"cLmXB__I1uOg","execution":{"iopub.status.busy":"2023-08-12T12:59:31.121949Z","iopub.execute_input":"2023-08-12T12:59:31.125218Z","iopub.status.idle":"2023-08-12T12:59:44.475016Z","shell.execute_reply.started":"2023-08-12T12:59:31.125168Z","shell.execute_reply":"2023-08-12T12:59:44.474054Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"label_to_class = {\n    0: 'none',\n    1: 'anger',\n    2: 'joy',\n    3: 'sadness',\n    4: 'love',\n    5: 'sympathy',\n    6: 'surprise',\n    7: 'fear'\n}\nclasses = ['none', 'anger', 'joy', 'sadness', 'love', 'sympathy', 'surprise', 'fear']","metadata":{"execution":{"iopub.status.busy":"2023-08-12T12:59:44.476647Z","iopub.execute_input":"2023-08-12T12:59:44.477527Z","iopub.status.idle":"2023-08-12T12:59:44.483681Z","shell.execute_reply.started":"2023-08-12T12:59:44.477480Z","shell.execute_reply":"2023-08-12T12:59:44.482452Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/train_final.pkl', 'rb') as f:\n    train = pickle.load(f)\n    \nwith open('/kaggle/working/val_final.pkl', 'rb') as f:\n    val = pickle.load(f)\n\nwith open('/kaggle/working/test_final.pkl', 'rb') as f:\n    test = pickle.load(f)\n\nwith open('/kaggle/working/train_embeddings_per_word.pkl', 'rb') as f:\n    train_embeddings = pickle.load(f)\n    \nwith open('/kaggle/working/val_embeddings_per_word.pkl', 'rb') as f:\n    val_embeddings = pickle.load(f)\n    \nwith open('/kaggle/working/test_embeddings_per_word.pkl', 'rb') as f:\n    test_embeddings = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T12:59:44.485126Z","iopub.execute_input":"2023-08-12T12:59:44.485839Z","iopub.status.idle":"2023-08-12T12:59:45.652509Z","shell.execute_reply.started":"2023-08-12T12:59:44.485806Z","shell.execute_reply":"2023-08-12T12:59:45.651474Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-12T12:59:45.654053Z","iopub.execute_input":"2023-08-12T12:59:45.654442Z","iopub.status.idle":"2023-08-12T12:59:45.663162Z","shell.execute_reply.started":"2023-08-12T12:59:45.654407Z","shell.execute_reply":"2023-08-12T12:59:45.662135Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(7045, 50, 768)"},"metadata":{}}]},{"cell_type":"code","source":"# X_train = train_embeddings.reshape(train_embeddings.shape[0], 1, train_embeddings.shape[1]) # reshape input to allow for GRU\n# X_val = val_embeddings.reshape(val_embeddings.shape[0], 1, val_embeddings.shape[1]) # reshape input to allow for GRU\n# X_test = test_embeddings.reshape(test_embeddings.shape[0], 1, test_embeddings.shape[1]) # reshape input to allow for GRU","metadata":{"execution":{"iopub.status.busy":"2023-08-12T12:59:55.310781Z","iopub.execute_input":"2023-08-12T12:59:55.311163Z","iopub.status.idle":"2023-08-12T12:59:55.315708Z","shell.execute_reply.started":"2023-08-12T12:59:55.311128Z","shell.execute_reply":"2023-08-12T12:59:55.314733Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train = train_embeddings\nX_val = val_embeddings\nX_test = test_embeddings","metadata":{"execution":{"iopub.status.busy":"2023-08-12T12:59:55.317948Z","iopub.execute_input":"2023-08-12T12:59:55.318564Z","iopub.status.idle":"2023-08-12T12:59:55.327756Z","shell.execute_reply.started":"2023-08-12T12:59:55.318531Z","shell.execute_reply":"2023-08-12T12:59:55.326658Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"encoder = OneHotEncoder()\n\ny_train = encoder.fit_transform(train['label'].values.reshape(-1,1)).toarray()\ny_val = encoder.fit_transform(val['label'].values.reshape(-1,1)).toarray()\ny_test = encoder.transform(test['label'].values.reshape(-1,1)).toarray()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T12:59:55.329194Z","iopub.execute_input":"2023-08-12T12:59:55.330254Z","iopub.status.idle":"2023-08-12T12:59:55.348785Z","shell.execute_reply.started":"2023-08-12T12:59:55.330217Z","shell.execute_reply":"2023-08-12T12:59:55.347777Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 128\nEPOCHS = 50\nEMBED_SIZE = 300\nLEARNING_RATE =  0.001\n\nearly_stopping_monitor = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0,\n    patience=10,\n    verbose=0,\n    mode='max',\n    baseline=None,\n    restore_best_weights=True)","metadata":{"id":"aNV13COwKUd5","execution":{"iopub.status.busy":"2023-08-12T12:59:55.350907Z","iopub.execute_input":"2023-08-12T12:59:55.351739Z","iopub.status.idle":"2023-08-12T12:59:55.357754Z","shell.execute_reply.started":"2023-08-12T12:59:55.351703Z","shell.execute_reply":"2023-08-12T12:59:55.356782Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def create_gru_model(model_type):\n    model = Sequential()\n#     model.add(Embedding(VOCAB_SIZE, EMBED_SIZE, input_length=max_length, trainable=True))\n    if model_type==1:\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)))\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512, return_sequences=True)))\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=False)))\n        model.add(Dropout(0.5))\n        model.add(Dense(128, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(64, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(8, activation='softmax'))\n    elif model_type==2:\n        model.add(tf.keras.layers.GRU(512, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n        model.add(tf.keras.layers.GRU(256, return_sequences=True))\n        model.add(tf.keras.layers.GRU(128, return_sequences=False))\n        model.add(Dense(128, activation='relu'))\n        model.add(Dropout(0.2))\n        model.add(Dense(64, activation='relu'))\n        model.add(Dropout(0.2))\n        model.add(Dense(8, activation='softmax'))\n    elif model_type==3:\n        model.add(tf.keras.layers.GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))\n        model.add(Dropout(0.5))\n        model.add(Flatten())\n        model.add(Dense(8, activation='softmax'))\n    elif model_type==4:\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False)))\n        model.add(Dropout(0.5))\n        model.add(Flatten())\n        model.add(Dense(8, activation='softmax'))\n    elif model_type==5:\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False)))\n        model.add(Dropout(0.5))\n        model.add(Dense(128, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(8, activation='softmax'))\n    \n    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n    # model.summary()\n\n    history = model.fit(X_train, np.asarray(y_train), validation_data=(X_val, np.asarray(y_val)), batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[early_stopping_monitor])\n    return model, history","metadata":{"execution":{"iopub.status.busy":"2023-08-12T12:59:55.359213Z","iopub.execute_input":"2023-08-12T12:59:55.359735Z","iopub.status.idle":"2023-08-12T12:59:55.378169Z","shell.execute_reply.started":"2023-08-12T12:59:55.359703Z","shell.execute_reply":"2023-08-12T12:59:55.377227Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for i in range(1,6):\n    model, _ = create_gru_model(i)\n    predictions = model.predict(X_test)\n    print('--------------------------------------------------------')\n    print()\n    print('CLassification report for model {}: '.format(i))\n    print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=classes))\n    print()\n    print('--------------------------------------------------------')","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:15:35.807786Z","iopub.execute_input":"2023-08-12T13:15:35.808196Z","iopub.status.idle":"2023-08-12T13:23:14.050127Z","shell.execute_reply.started":"2023-08-12T13:15:35.808161Z","shell.execute_reply":"2023-08-12T13:23:14.048896Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/50\n56/56 [==============================] - 23s 168ms/step - loss: 2.1115 - accuracy: 0.1750 - val_loss: 1.9945 - val_accuracy: 0.2636\nEpoch 2/50\n56/56 [==============================] - 6s 116ms/step - loss: 1.9327 - accuracy: 0.2531 - val_loss: 1.7379 - val_accuracy: 0.3748\nEpoch 3/50\n56/56 [==============================] - 6s 116ms/step - loss: 1.7978 - accuracy: 0.3182 - val_loss: 1.6867 - val_accuracy: 0.3907\nEpoch 4/50\n56/56 [==============================] - 7s 117ms/step - loss: 1.7468 - accuracy: 0.3459 - val_loss: 1.5653 - val_accuracy: 0.4477\nEpoch 5/50\n56/56 [==============================] - 6s 116ms/step - loss: 1.6478 - accuracy: 0.3882 - val_loss: 1.5835 - val_accuracy: 0.4225\nEpoch 6/50\n56/56 [==============================] - 6s 115ms/step - loss: 1.6000 - accuracy: 0.4135 - val_loss: 1.5255 - val_accuracy: 0.4371\nEpoch 7/50\n56/56 [==============================] - 7s 116ms/step - loss: 1.5683 - accuracy: 0.4244 - val_loss: 1.5295 - val_accuracy: 0.4450\nEpoch 8/50\n56/56 [==============================] - 7s 117ms/step - loss: 1.5574 - accuracy: 0.4206 - val_loss: 1.4797 - val_accuracy: 0.4589\nEpoch 9/50\n56/56 [==============================] - 6s 115ms/step - loss: 1.4959 - accuracy: 0.4531 - val_loss: 1.4848 - val_accuracy: 0.4411\nEpoch 10/50\n56/56 [==============================] - 6s 116ms/step - loss: 1.4640 - accuracy: 0.4632 - val_loss: 1.4537 - val_accuracy: 0.4781\nEpoch 11/50\n56/56 [==============================] - 7s 116ms/step - loss: 1.4312 - accuracy: 0.4755 - val_loss: 1.4321 - val_accuracy: 0.5119\nEpoch 12/50\n56/56 [==============================] - 6s 116ms/step - loss: 1.3879 - accuracy: 0.4951 - val_loss: 1.4141 - val_accuracy: 0.5139\nEpoch 13/50\n56/56 [==============================] - 7s 118ms/step - loss: 1.3749 - accuracy: 0.5111 - val_loss: 1.3740 - val_accuracy: 0.5272\nEpoch 14/50\n56/56 [==============================] - 6s 116ms/step - loss: 1.2973 - accuracy: 0.5435 - val_loss: 1.3895 - val_accuracy: 0.5192\nEpoch 15/50\n56/56 [==============================] - 7s 116ms/step - loss: 1.2475 - accuracy: 0.5693 - val_loss: 1.3017 - val_accuracy: 0.5364\nEpoch 16/50\n56/56 [==============================] - 7s 116ms/step - loss: 1.2029 - accuracy: 0.5789 - val_loss: 1.3655 - val_accuracy: 0.5477\nEpoch 17/50\n56/56 [==============================] - 6s 116ms/step - loss: 1.1789 - accuracy: 0.6044 - val_loss: 1.3094 - val_accuracy: 0.5530\nEpoch 18/50\n56/56 [==============================] - 7s 117ms/step - loss: 1.1489 - accuracy: 0.6030 - val_loss: 1.4187 - val_accuracy: 0.5583\nEpoch 19/50\n56/56 [==============================] - 6s 116ms/step - loss: 1.1012 - accuracy: 0.6341 - val_loss: 1.3684 - val_accuracy: 0.5609\nEpoch 20/50\n56/56 [==============================] - 7s 116ms/step - loss: 1.0491 - accuracy: 0.6436 - val_loss: 1.4467 - val_accuracy: 0.5583\nEpoch 21/50\n56/56 [==============================] - 6s 115ms/step - loss: 1.0017 - accuracy: 0.6571 - val_loss: 1.3976 - val_accuracy: 0.5563\nEpoch 22/50\n56/56 [==============================] - 6s 115ms/step - loss: 0.9465 - accuracy: 0.6798 - val_loss: 1.4328 - val_accuracy: 0.5636\nEpoch 23/50\n56/56 [==============================] - 7s 117ms/step - loss: 0.9716 - accuracy: 0.6847 - val_loss: 1.4393 - val_accuracy: 0.5709\nEpoch 24/50\n56/56 [==============================] - 6s 115ms/step - loss: 0.8985 - accuracy: 0.6998 - val_loss: 1.4273 - val_accuracy: 0.5682\nEpoch 25/50\n56/56 [==============================] - 6s 116ms/step - loss: 0.8327 - accuracy: 0.7231 - val_loss: 1.4873 - val_accuracy: 0.5755\nEpoch 26/50\n56/56 [==============================] - 7s 116ms/step - loss: 0.8666 - accuracy: 0.7127 - val_loss: 1.5944 - val_accuracy: 0.5728\nEpoch 27/50\n56/56 [==============================] - 7s 117ms/step - loss: 0.7319 - accuracy: 0.7618 - val_loss: 1.6299 - val_accuracy: 0.5728\nEpoch 28/50\n56/56 [==============================] - 7s 117ms/step - loss: 0.6902 - accuracy: 0.7837 - val_loss: 1.6870 - val_accuracy: 0.5682\nEpoch 29/50\n56/56 [==============================] - 6s 116ms/step - loss: 0.6540 - accuracy: 0.7874 - val_loss: 1.8556 - val_accuracy: 0.5596\nEpoch 30/50\n56/56 [==============================] - 6s 116ms/step - loss: 0.6889 - accuracy: 0.7821 - val_loss: 1.8327 - val_accuracy: 0.5596\nEpoch 31/50\n56/56 [==============================] - 6s 116ms/step - loss: 0.5530 - accuracy: 0.8236 - val_loss: 2.1353 - val_accuracy: 0.5543\nEpoch 32/50\n56/56 [==============================] - 6s 115ms/step - loss: 0.4854 - accuracy: 0.8457 - val_loss: 2.0990 - val_accuracy: 0.5311\nEpoch 33/50\n56/56 [==============================] - 7s 118ms/step - loss: 0.5518 - accuracy: 0.8282 - val_loss: 2.1333 - val_accuracy: 0.5636\nEpoch 34/50\n56/56 [==============================] - 6s 114ms/step - loss: 0.4572 - accuracy: 0.8585 - val_loss: 2.3250 - val_accuracy: 0.5510\nEpoch 35/50\n56/56 [==============================] - 7s 117ms/step - loss: 0.4013 - accuracy: 0.8789 - val_loss: 2.4129 - val_accuracy: 0.5497\n48/48 [==============================] - 3s 19ms/step\n--------------------------------------------------------\n\nCLassification report for model 1: \n              precision    recall  f1-score   support\n\n        none       0.60      0.82      0.69       229\n       anger       0.48      0.74      0.58       200\n         joy       0.47      0.42      0.45       205\n     sadness       0.41      0.30      0.35       185\n        love       0.78      0.48      0.60       193\n    sympathy       0.66      0.70      0.68       156\n    surprise       0.36      0.29      0.32       154\n        fear       0.86      0.76      0.80       188\n\n    accuracy                           0.57      1510\n   macro avg       0.58      0.56      0.56      1510\nweighted avg       0.58      0.57      0.56      1510\n\n\n--------------------------------------------------------\nEpoch 1/50\n56/56 [==============================] - 10s 73ms/step - loss: 1.7680 - accuracy: 0.3463 - val_loss: 1.4239 - val_accuracy: 0.5073\nEpoch 2/50\n56/56 [==============================] - 3s 46ms/step - loss: 1.3523 - accuracy: 0.5334 - val_loss: 1.3072 - val_accuracy: 0.5364\nEpoch 3/50\n56/56 [==============================] - 3s 46ms/step - loss: 1.2268 - accuracy: 0.5858 - val_loss: 1.2344 - val_accuracy: 0.5762\nEpoch 4/50\n56/56 [==============================] - 3s 47ms/step - loss: 1.1332 - accuracy: 0.6193 - val_loss: 1.1924 - val_accuracy: 0.5795\nEpoch 5/50\n56/56 [==============================] - 3s 46ms/step - loss: 1.0709 - accuracy: 0.6417 - val_loss: 1.2188 - val_accuracy: 0.5656\nEpoch 6/50\n56/56 [==============================] - 3s 46ms/step - loss: 1.0543 - accuracy: 0.6436 - val_loss: 1.2401 - val_accuracy: 0.5642\nEpoch 7/50\n56/56 [==============================] - 3s 45ms/step - loss: 1.0304 - accuracy: 0.6478 - val_loss: 1.1863 - val_accuracy: 0.5815\nEpoch 8/50\n56/56 [==============================] - 3s 46ms/step - loss: 0.9599 - accuracy: 0.6714 - val_loss: 1.1777 - val_accuracy: 0.5887\nEpoch 9/50\n56/56 [==============================] - 3s 46ms/step - loss: 0.9213 - accuracy: 0.6890 - val_loss: 1.2044 - val_accuracy: 0.5689\nEpoch 10/50\n56/56 [==============================] - 3s 45ms/step - loss: 0.9067 - accuracy: 0.6908 - val_loss: 1.3150 - val_accuracy: 0.5748\nEpoch 11/50\n56/56 [==============================] - 3s 45ms/step - loss: 0.9272 - accuracy: 0.6845 - val_loss: 1.2238 - val_accuracy: 0.5728\nEpoch 12/50\n56/56 [==============================] - 3s 45ms/step - loss: 0.8481 - accuracy: 0.7153 - val_loss: 1.2272 - val_accuracy: 0.5967\nEpoch 13/50\n56/56 [==============================] - 3s 49ms/step - loss: 0.7578 - accuracy: 0.7451 - val_loss: 1.2848 - val_accuracy: 0.5914\nEpoch 14/50\n56/56 [==============================] - 3s 46ms/step - loss: 0.7421 - accuracy: 0.7486 - val_loss: 1.2820 - val_accuracy: 0.5921\nEpoch 15/50\n56/56 [==============================] - 3s 45ms/step - loss: 0.6873 - accuracy: 0.7637 - val_loss: 1.5433 - val_accuracy: 0.5748\nEpoch 16/50\n56/56 [==============================] - 3s 45ms/step - loss: 0.6913 - accuracy: 0.7642 - val_loss: 1.4481 - val_accuracy: 0.5874\nEpoch 17/50\n56/56 [==============================] - 3s 45ms/step - loss: 0.5755 - accuracy: 0.8041 - val_loss: 1.4824 - val_accuracy: 0.5808\nEpoch 18/50\n56/56 [==============================] - 3s 46ms/step - loss: 0.5620 - accuracy: 0.8126 - val_loss: 1.5666 - val_accuracy: 0.5854\nEpoch 19/50\n56/56 [==============================] - 3s 45ms/step - loss: 0.4890 - accuracy: 0.8335 - val_loss: 1.6563 - val_accuracy: 0.5887\nEpoch 20/50\n56/56 [==============================] - 3s 46ms/step - loss: 0.4078 - accuracy: 0.8608 - val_loss: 1.8632 - val_accuracy: 0.5543\nEpoch 21/50\n56/56 [==============================] - 3s 46ms/step - loss: 0.3853 - accuracy: 0.8711 - val_loss: 1.8918 - val_accuracy: 0.5709\nEpoch 22/50\n56/56 [==============================] - 3s 46ms/step - loss: 0.3124 - accuracy: 0.8924 - val_loss: 2.1435 - val_accuracy: 0.5536\n48/48 [==============================] - 1s 8ms/step\n--------------------------------------------------------\n\nCLassification report for model 2: \n              precision    recall  f1-score   support\n\n        none       0.59      0.79      0.68       229\n       anger       0.56      0.68      0.62       200\n         joy       0.43      0.43      0.43       205\n     sadness       0.42      0.46      0.44       185\n        love       0.71      0.62      0.66       193\n    sympathy       0.79      0.67      0.72       156\n    surprise       0.51      0.29      0.37       154\n        fear       0.86      0.80      0.83       188\n\n    accuracy                           0.60      1510\n   macro avg       0.61      0.59      0.59      1510\nweighted avg       0.61      0.60      0.60      1510\n\n\n--------------------------------------------------------\nEpoch 1/50\n56/56 [==============================] - 5s 43ms/step - loss: 1.6987 - accuracy: 0.3815 - val_loss: 1.3378 - val_accuracy: 0.5219\nEpoch 2/50\n56/56 [==============================] - 1s 23ms/step - loss: 1.2797 - accuracy: 0.5557 - val_loss: 1.2035 - val_accuracy: 0.5623\nEpoch 3/50\n56/56 [==============================] - 1s 21ms/step - loss: 1.1600 - accuracy: 0.5976 - val_loss: 1.1927 - val_accuracy: 0.5755\nEpoch 4/50\n56/56 [==============================] - 1s 20ms/step - loss: 1.0980 - accuracy: 0.6250 - val_loss: 1.1615 - val_accuracy: 0.5788\nEpoch 5/50\n56/56 [==============================] - 1s 20ms/step - loss: 1.0363 - accuracy: 0.6365 - val_loss: 1.1380 - val_accuracy: 0.5980\nEpoch 6/50\n56/56 [==============================] - 1s 21ms/step - loss: 1.0038 - accuracy: 0.6485 - val_loss: 1.1493 - val_accuracy: 0.5993\nEpoch 7/50\n56/56 [==============================] - 1s 20ms/step - loss: 0.9784 - accuracy: 0.6532 - val_loss: 1.1427 - val_accuracy: 0.5927\nEpoch 8/50\n56/56 [==============================] - 1s 22ms/step - loss: 0.9416 - accuracy: 0.6727 - val_loss: 1.2713 - val_accuracy: 0.5530\nEpoch 9/50\n56/56 [==============================] - 1s 20ms/step - loss: 0.9750 - accuracy: 0.6568 - val_loss: 1.1529 - val_accuracy: 0.5940\nEpoch 10/50\n56/56 [==============================] - 1s 23ms/step - loss: 0.8914 - accuracy: 0.6859 - val_loss: 1.2357 - val_accuracy: 0.5662\nEpoch 11/50\n56/56 [==============================] - 1s 21ms/step - loss: 0.9182 - accuracy: 0.6775 - val_loss: 1.1866 - val_accuracy: 0.5947\nEpoch 12/50\n56/56 [==============================] - 1s 23ms/step - loss: 0.8394 - accuracy: 0.7039 - val_loss: 1.2017 - val_accuracy: 0.5921\nEpoch 13/50\n56/56 [==============================] - 1s 23ms/step - loss: 0.8056 - accuracy: 0.7228 - val_loss: 1.1758 - val_accuracy: 0.5967\nEpoch 14/50\n56/56 [==============================] - 1s 21ms/step - loss: 0.8081 - accuracy: 0.7124 - val_loss: 1.1821 - val_accuracy: 0.5947\nEpoch 15/50\n56/56 [==============================] - 1s 20ms/step - loss: 0.7903 - accuracy: 0.7239 - val_loss: 1.2095 - val_accuracy: 0.5960\nEpoch 16/50\n56/56 [==============================] - 1s 23ms/step - loss: 0.7527 - accuracy: 0.7330 - val_loss: 1.3210 - val_accuracy: 0.5702\n48/48 [==============================] - 1s 4ms/step\n--------------------------------------------------------\n\nCLassification report for model 3: \n              precision    recall  f1-score   support\n\n        none       0.56      0.86      0.68       229\n       anger       0.61      0.64      0.62       200\n         joy       0.41      0.56      0.47       205\n     sadness       0.62      0.33      0.43       185\n        love       0.71      0.60      0.65       193\n    sympathy       0.71      0.74      0.72       156\n    surprise       0.49      0.23      0.31       154\n        fear       0.83      0.77      0.80       188\n\n    accuracy                           0.60      1510\n   macro avg       0.62      0.59      0.59      1510\nweighted avg       0.61      0.60      0.59      1510\n\n\n--------------------------------------------------------\nEpoch 1/50\n56/56 [==============================] - 8s 48ms/step - loss: 1.5961 - accuracy: 0.4352 - val_loss: 1.2604 - val_accuracy: 0.5616\nEpoch 2/50\n56/56 [==============================] - 2s 30ms/step - loss: 1.1938 - accuracy: 0.5779 - val_loss: 1.1914 - val_accuracy: 0.5801\nEpoch 3/50\n56/56 [==============================] - 2s 29ms/step - loss: 1.1038 - accuracy: 0.6153 - val_loss: 1.1773 - val_accuracy: 0.5702\nEpoch 4/50\n56/56 [==============================] - 1s 25ms/step - loss: 1.0507 - accuracy: 0.6290 - val_loss: 1.1663 - val_accuracy: 0.5861\nEpoch 5/50\n56/56 [==============================] - 1s 26ms/step - loss: 0.9985 - accuracy: 0.6511 - val_loss: 1.1219 - val_accuracy: 0.5881\nEpoch 6/50\n56/56 [==============================] - 1s 25ms/step - loss: 0.9570 - accuracy: 0.6605 - val_loss: 1.1460 - val_accuracy: 0.5894\nEpoch 7/50\n56/56 [==============================] - 2s 28ms/step - loss: 0.9233 - accuracy: 0.6742 - val_loss: 1.1344 - val_accuracy: 0.5914\nEpoch 8/50\n56/56 [==============================] - 1s 26ms/step - loss: 0.8974 - accuracy: 0.6805 - val_loss: 1.1418 - val_accuracy: 0.5715\nEpoch 9/50\n56/56 [==============================] - 1s 26ms/step - loss: 0.8673 - accuracy: 0.6903 - val_loss: 1.1207 - val_accuracy: 0.5993\nEpoch 10/50\n56/56 [==============================] - 1s 26ms/step - loss: 0.8344 - accuracy: 0.7110 - val_loss: 1.1275 - val_accuracy: 0.6020\nEpoch 11/50\n56/56 [==============================] - 1s 26ms/step - loss: 0.8188 - accuracy: 0.7133 - val_loss: 1.1605 - val_accuracy: 0.5874\nEpoch 12/50\n56/56 [==============================] - 1s 26ms/step - loss: 0.7773 - accuracy: 0.7248 - val_loss: 1.1769 - val_accuracy: 0.6060\nEpoch 13/50\n56/56 [==============================] - 2s 28ms/step - loss: 0.7587 - accuracy: 0.7313 - val_loss: 1.2322 - val_accuracy: 0.5947\nEpoch 14/50\n56/56 [==============================] - 1s 27ms/step - loss: 0.7411 - accuracy: 0.7366 - val_loss: 1.1984 - val_accuracy: 0.6033\nEpoch 15/50\n56/56 [==============================] - 2s 28ms/step - loss: 0.7039 - accuracy: 0.7506 - val_loss: 1.1952 - val_accuracy: 0.6033\nEpoch 16/50\n56/56 [==============================] - 2s 28ms/step - loss: 0.6458 - accuracy: 0.7710 - val_loss: 1.2471 - val_accuracy: 0.5947\nEpoch 17/50\n56/56 [==============================] - 1s 26ms/step - loss: 0.6400 - accuracy: 0.7713 - val_loss: 1.2577 - val_accuracy: 0.5894\nEpoch 18/50\n56/56 [==============================] - 1s 26ms/step - loss: 0.5937 - accuracy: 0.7862 - val_loss: 1.2512 - val_accuracy: 0.6053\nEpoch 19/50\n56/56 [==============================] - 1s 26ms/step - loss: 0.5617 - accuracy: 0.8054 - val_loss: 1.3430 - val_accuracy: 0.5775\nEpoch 20/50\n56/56 [==============================] - 1s 26ms/step - loss: 0.6087 - accuracy: 0.7794 - val_loss: 1.3080 - val_accuracy: 0.6007\nEpoch 21/50\n56/56 [==============================] - 2s 29ms/step - loss: 0.5301 - accuracy: 0.8106 - val_loss: 1.3349 - val_accuracy: 0.5921\nEpoch 22/50\n56/56 [==============================] - 2s 28ms/step - loss: 0.5033 - accuracy: 0.8136 - val_loss: 1.4011 - val_accuracy: 0.5775\n48/48 [==============================] - 1s 6ms/step\n--------------------------------------------------------\n\nCLassification report for model 4: \n              precision    recall  f1-score   support\n\n        none       0.57      0.86      0.68       229\n       anger       0.57      0.69      0.63       200\n         joy       0.56      0.37      0.44       205\n     sadness       0.48      0.35      0.40       185\n        love       0.67      0.73      0.70       193\n    sympathy       0.80      0.61      0.69       156\n    surprise       0.46      0.40      0.43       154\n        fear       0.82      0.82      0.82       188\n\n    accuracy                           0.61      1510\n   macro avg       0.61      0.60      0.60      1510\nweighted avg       0.61      0.61      0.60      1510\n\n\n--------------------------------------------------------\nEpoch 1/50\n56/56 [==============================] - 7s 52ms/step - loss: 1.7998 - accuracy: 0.3347 - val_loss: 1.3755 - val_accuracy: 0.5205\nEpoch 2/50\n56/56 [==============================] - 2s 34ms/step - loss: 1.3611 - accuracy: 0.5209 - val_loss: 1.2197 - val_accuracy: 0.5682\nEpoch 3/50\n56/56 [==============================] - 2s 33ms/step - loss: 1.2145 - accuracy: 0.5763 - val_loss: 1.1822 - val_accuracy: 0.5629\nEpoch 4/50\n56/56 [==============================] - 2s 34ms/step - loss: 1.1318 - accuracy: 0.6072 - val_loss: 1.1379 - val_accuracy: 0.5861\nEpoch 5/50\n56/56 [==============================] - 2s 35ms/step - loss: 1.0722 - accuracy: 0.6268 - val_loss: 1.1212 - val_accuracy: 0.5967\nEpoch 6/50\n56/56 [==============================] - 2s 32ms/step - loss: 1.0537 - accuracy: 0.6292 - val_loss: 1.1450 - val_accuracy: 0.5901\nEpoch 7/50\n56/56 [==============================] - 2s 34ms/step - loss: 0.9836 - accuracy: 0.6552 - val_loss: 1.1795 - val_accuracy: 0.5795\nEpoch 8/50\n56/56 [==============================] - 2s 34ms/step - loss: 0.9633 - accuracy: 0.6653 - val_loss: 1.1267 - val_accuracy: 0.6026\nEpoch 9/50\n56/56 [==============================] - 2s 34ms/step - loss: 0.9269 - accuracy: 0.6701 - val_loss: 1.1620 - val_accuracy: 0.5815\nEpoch 10/50\n56/56 [==============================] - 2s 33ms/step - loss: 0.9026 - accuracy: 0.6830 - val_loss: 1.1281 - val_accuracy: 0.6106\nEpoch 11/50\n56/56 [==============================] - 2s 32ms/step - loss: 0.8325 - accuracy: 0.7073 - val_loss: 1.1911 - val_accuracy: 0.5960\nEpoch 12/50\n56/56 [==============================] - 2s 32ms/step - loss: 0.8396 - accuracy: 0.7019 - val_loss: 1.1982 - val_accuracy: 0.5868\nEpoch 13/50\n56/56 [==============================] - 2s 38ms/step - loss: 0.8056 - accuracy: 0.7148 - val_loss: 1.1739 - val_accuracy: 0.6146\nEpoch 14/50\n56/56 [==============================] - 2s 32ms/step - loss: 0.7949 - accuracy: 0.7165 - val_loss: 1.1782 - val_accuracy: 0.6020\nEpoch 15/50\n56/56 [==============================] - 2s 33ms/step - loss: 0.7762 - accuracy: 0.7189 - val_loss: 1.1945 - val_accuracy: 0.6040\nEpoch 16/50\n56/56 [==============================] - 2s 32ms/step - loss: 0.7163 - accuracy: 0.7391 - val_loss: 1.1927 - val_accuracy: 0.6113\nEpoch 17/50\n56/56 [==============================] - 2s 33ms/step - loss: 0.6987 - accuracy: 0.7478 - val_loss: 1.2163 - val_accuracy: 0.6132\nEpoch 18/50\n56/56 [==============================] - 2s 32ms/step - loss: 0.6383 - accuracy: 0.7691 - val_loss: 1.2335 - val_accuracy: 0.5934\nEpoch 19/50\n56/56 [==============================] - 2s 34ms/step - loss: 0.6334 - accuracy: 0.7715 - val_loss: 1.3247 - val_accuracy: 0.5947\nEpoch 20/50\n56/56 [==============================] - 2s 34ms/step - loss: 0.6345 - accuracy: 0.7742 - val_loss: 1.2680 - val_accuracy: 0.6066\nEpoch 21/50\n56/56 [==============================] - 2s 33ms/step - loss: 0.5788 - accuracy: 0.7884 - val_loss: 1.3495 - val_accuracy: 0.6106\nEpoch 22/50\n56/56 [==============================] - 2s 32ms/step - loss: 0.5445 - accuracy: 0.8007 - val_loss: 1.4303 - val_accuracy: 0.5901\nEpoch 23/50\n56/56 [==============================] - 2s 33ms/step - loss: 0.5230 - accuracy: 0.8098 - val_loss: 1.4513 - val_accuracy: 0.6166\nEpoch 24/50\n56/56 [==============================] - 2s 34ms/step - loss: 0.5200 - accuracy: 0.8115 - val_loss: 1.5191 - val_accuracy: 0.6013\nEpoch 25/50\n56/56 [==============================] - 2s 32ms/step - loss: 0.5051 - accuracy: 0.8165 - val_loss: 1.3840 - val_accuracy: 0.6046\nEpoch 26/50\n56/56 [==============================] - 2s 33ms/step - loss: 0.4603 - accuracy: 0.8297 - val_loss: 1.5364 - val_accuracy: 0.5954\nEpoch 27/50\n56/56 [==============================] - 2s 34ms/step - loss: 0.4439 - accuracy: 0.8362 - val_loss: 1.5427 - val_accuracy: 0.6007\nEpoch 28/50\n56/56 [==============================] - 2s 34ms/step - loss: 0.4368 - accuracy: 0.8380 - val_loss: 1.6420 - val_accuracy: 0.6000\nEpoch 29/50\n56/56 [==============================] - 2s 32ms/step - loss: 0.3921 - accuracy: 0.8549 - val_loss: 1.7838 - val_accuracy: 0.6026\nEpoch 30/50\n56/56 [==============================] - 2s 37ms/step - loss: 0.3980 - accuracy: 0.8545 - val_loss: 1.6742 - val_accuracy: 0.5927\nEpoch 31/50\n56/56 [==============================] - 2s 35ms/step - loss: 0.3257 - accuracy: 0.8799 - val_loss: 2.0022 - val_accuracy: 0.5940\nEpoch 32/50\n56/56 [==============================] - 2s 34ms/step - loss: 0.3402 - accuracy: 0.8720 - val_loss: 1.9032 - val_accuracy: 0.5894\nEpoch 33/50\n56/56 [==============================] - 2s 33ms/step - loss: 0.3189 - accuracy: 0.8864 - val_loss: 1.7748 - val_accuracy: 0.6113\n48/48 [==============================] - 1s 6ms/step\n--------------------------------------------------------\n\nCLassification report for model 5: \n              precision    recall  f1-score   support\n\n        none       0.62      0.77      0.68       229\n       anger       0.55      0.71      0.62       200\n         joy       0.49      0.48      0.48       205\n     sadness       0.49      0.38      0.43       185\n        love       0.67      0.70      0.69       193\n    sympathy       0.74      0.61      0.67       156\n    surprise       0.48      0.40      0.43       154\n        fear       0.90      0.75      0.82       188\n\n    accuracy                           0.61      1510\n   macro avg       0.62      0.60      0.60      1510\nweighted avg       0.61      0.61      0.61      1510\n\n\n--------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}