{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install gdown","metadata":{"id":"FtXnDFfR4_2b","outputId":"4e6de28f-8ba8-4e49-b0c3-21acba14110f","execution":{"iopub.status.busy":"2023-08-12T13:25:51.127066Z","iopub.execute_input":"2023-08-12T13:25:51.127910Z","iopub.status.idle":"2023-08-12T13:26:05.463649Z","shell.execute_reply.started":"2023-08-12T13:25:51.127875Z","shell.execute_reply":"2023-08-12T13:26:05.462382Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.65.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"train = '1HqceFWkRXwEqgPcuAtACFVvHhKO_TGG6'\nval = '1XEsLOUFJTnCGcitk4IUS23H6IlzCzwqZ'\ntest = '1Lu5ItQvj2iGRqMXJ-bovQkys0eilR9HZ'\n\ntrain_embeddings_per_word = '1-0Bb3pLy_EhEggA-VsOh8TIS92VbmmxV'\nval_embeddings_per_word = '1-0WpebJIz9q2PZ_Baf51ZUsiBx9pWVJP'\ntest_embeddings_per_word = '1pi6DGhZ7AoGzC3cqP-ET5Qvkc3HD33bo'\n\ntrain_embeddings_per_sentence = '1-260zeDhoDdxQ3McfR7Hr4c6mfaLFBpa'\nval_embeddings_per_sentence = '1-2EN_l5NcdgJZ740Szt4g6RcIZ9GX_D2'\ntest_embeddings_per_sentence = '1gNKahNHussBAV-6mFyC66AxPTA0YhQAG'","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:26:05.466100Z","iopub.execute_input":"2023-08-12T13:26:05.466495Z","iopub.status.idle":"2023-08-12T13:26:05.472267Z","shell.execute_reply.started":"2023-08-12T13:26:05.466459Z","shell.execute_reply":"2023-08-12T13:26:05.471373Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!gdown {train}\n!gdown {val}\n!gdown {test}\n\n!gdown {train_embeddings_per_sentence}\n!gdown {val_embeddings_per_sentence}\n!gdown {test_embeddings_per_sentence}","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:26:05.473755Z","iopub.execute_input":"2023-08-12T13:26:05.474135Z","iopub.status.idle":"2023-08-12T13:26:22.824720Z","shell.execute_reply.started":"2023-08-12T13:26:05.474100Z","shell.execute_reply":"2023-08-12T13:26:22.823336Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1HqceFWkRXwEqgPcuAtACFVvHhKO_TGG6\nTo: /kaggle/working/train_final.pkl\n100%|███████████████████████████████████████| 3.47M/3.47M [00:00<00:00, 182MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1XEsLOUFJTnCGcitk4IUS23H6IlzCzwqZ\nTo: /kaggle/working/val_final.pkl\n100%|█████████████████████████████████████████| 743k/743k [00:00<00:00, 122MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1Lu5ItQvj2iGRqMXJ-bovQkys0eilR9HZ\nTo: /kaggle/working/test_final.pkl\n100%|█████████████████████████████████████████| 737k/737k [00:00<00:00, 121MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1-260zeDhoDdxQ3McfR7Hr4c6mfaLFBpa\nTo: /kaggle/working/train_embeddings_per_sentence.pkl\n100%|██████████████████████████████████████| 21.6M/21.6M [00:00<00:00, 74.2MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1-2EN_l5NcdgJZ740Szt4g6RcIZ9GX_D2\nTo: /kaggle/working/val_embeddings_per_sentence.pkl\n100%|██████████████████████████████████████| 4.64M/4.64M [00:00<00:00, 38.2MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1gNKahNHussBAV-6mFyC66AxPTA0YhQAG\nTo: /kaggle/working/test_embeddings_per_sentence.pkl\n100%|██████████████████████████████████████| 4.64M/4.64M [00:00<00:00, 23.6MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nimport string\nimport re\nimport pickle\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.isri import ISRIStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import confusion_matrix,accuracy_score, classification_report\nfrom sklearn.svm import SVC\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.layers import MaxPooling1D\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import backend as K\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nimport seaborn as sns\nimport torch\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing import sequence\nfrom collections import OrderedDict\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"id":"cLmXB__I1uOg","execution":{"iopub.status.busy":"2023-08-12T13:26:22.828131Z","iopub.execute_input":"2023-08-12T13:26:22.828513Z","iopub.status.idle":"2023-08-12T13:26:35.187563Z","shell.execute_reply.started":"2023-08-12T13:26:22.828469Z","shell.execute_reply":"2023-08-12T13:26:35.186583Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"label_to_class = {\n    0: 'none',\n    1: 'anger',\n    2: 'joy',\n    3: 'sadness',\n    4: 'love',\n    5: 'sympathy',\n    6: 'surprise',\n    7: 'fear'\n}\nclasses = ['none', 'anger', 'joy', 'sadness', 'love', 'sympathy', 'surprise', 'fear']","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:26:35.188772Z","iopub.execute_input":"2023-08-12T13:26:35.189514Z","iopub.status.idle":"2023-08-12T13:26:35.194665Z","shell.execute_reply.started":"2023-08-12T13:26:35.189459Z","shell.execute_reply":"2023-08-12T13:26:35.193682Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/train_final.pkl', 'rb') as f:\n    train = pickle.load(f)\n    \nwith open('/kaggle/working/val_final.pkl', 'rb') as f:\n    val = pickle.load(f)\n\nwith open('/kaggle/working/test_final.pkl', 'rb') as f:\n    test = pickle.load(f)\n\nwith open('/kaggle/working/train_embeddings_per_sentence.pkl', 'rb') as f:\n    train_embeddings = pickle.load(f)\n    \nwith open('/kaggle/working/val_embeddings_per_sentence.pkl', 'rb') as f:\n    val_embeddings = pickle.load(f)\n    \nwith open('/kaggle/working/test_embeddings_per_sentence.pkl', 'rb') as f:\n    test_embeddings = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:27:10.196281Z","iopub.execute_input":"2023-08-12T13:27:10.197482Z","iopub.status.idle":"2023-08-12T13:27:10.254636Z","shell.execute_reply.started":"2023-08-12T13:27:10.197445Z","shell.execute_reply":"2023-08-12T13:27:10.253661Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_train = train_embeddings.reshape(train_embeddings.shape[0], 1, train_embeddings.shape[1]) # reshape input to allow for GRU\nX_val = val_embeddings.reshape(val_embeddings.shape[0], 1, val_embeddings.shape[1]) # reshape input to allow for GRU\nX_test = test_embeddings.reshape(test_embeddings.shape[0], 1, test_embeddings.shape[1]) # reshape input to allow for GRU","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:27:10.256676Z","iopub.execute_input":"2023-08-12T13:27:10.257114Z","iopub.status.idle":"2023-08-12T13:27:10.262860Z","shell.execute_reply.started":"2023-08-12T13:27:10.257080Z","shell.execute_reply":"2023-08-12T13:27:10.261873Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"encoder = OneHotEncoder()\n\ny_train = encoder.fit_transform(train['label'].values.reshape(-1,1)).toarray()\ny_val = encoder.fit_transform(val['label'].values.reshape(-1,1)).toarray()\ny_test = encoder.transform(test['label'].values.reshape(-1,1)).toarray()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:27:10.264435Z","iopub.execute_input":"2023-08-12T13:27:10.265094Z","iopub.status.idle":"2023-08-12T13:27:10.284452Z","shell.execute_reply.started":"2023-08-12T13:27:10.265061Z","shell.execute_reply":"2023-08-12T13:27:10.283540Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 128\nEPOCHS = 50\nEMBED_SIZE = 300\nLEARNING_RATE =  0.001\n\nearly_stopping_monitor = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0,\n    patience=10,\n    verbose=0,\n    mode='max',\n    baseline=None,\n    restore_best_weights=True)","metadata":{"id":"aNV13COwKUd5","execution":{"iopub.status.busy":"2023-08-12T13:27:10.286737Z","iopub.execute_input":"2023-08-12T13:27:10.287590Z","iopub.status.idle":"2023-08-12T13:27:10.293222Z","shell.execute_reply.started":"2023-08-12T13:27:10.287558Z","shell.execute_reply":"2023-08-12T13:27:10.292067Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def create_gru_model(model_type):\n    model = Sequential()\n#     model.add(Embedding(VOCAB_SIZE, EMBED_SIZE, input_length=max_length, trainable=True))\n    if model_type==1:\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)))\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512, return_sequences=True)))\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=False)))\n        model.add(Dropout(0.5))\n        model.add(Dense(128, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(64, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(8, activation='softmax'))\n    elif model_type==2:\n        model.add(tf.keras.layers.GRU(512, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n        model.add(tf.keras.layers.GRU(256, return_sequences=True))\n        model.add(tf.keras.layers.GRU(128, return_sequences=False))\n        model.add(Dense(128, activation='relu'))\n        model.add(Dropout(0.2))\n        model.add(Dense(64, activation='relu'))\n        model.add(Dropout(0.2))\n        model.add(Dense(8, activation='softmax'))\n    elif model_type==3:\n        model.add(tf.keras.layers.GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))\n        model.add(Dropout(0.5))\n        model.add(Flatten())\n        model.add(Dense(8, activation='softmax'))\n    elif model_type==4:\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False)))\n        model.add(Dropout(0.5))\n        model.add(Flatten())\n        model.add(Dense(8, activation='softmax'))\n    elif model_type==5:\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False)))\n        model.add(Dropout(0.5))\n        model.add(Dense(128, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(8, activation='softmax'))\n    \n    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n    # model.summary()\n\n    history = model.fit(X_train, np.asarray(y_train), validation_data=(X_val, np.asarray(y_val)), batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[early_stopping_monitor])\n    return model, history","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:27:10.295330Z","iopub.execute_input":"2023-08-12T13:27:10.295705Z","iopub.status.idle":"2023-08-12T13:27:10.315837Z","shell.execute_reply.started":"2023-08-12T13:27:10.295675Z","shell.execute_reply":"2023-08-12T13:27:10.314729Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for i in range(1,6):\n    model, _ = create_gru_model(i)\n    predictions = model.predict(X_test)\n    print('--------------------------------------------------------')\n    print()\n    print('CLassification report for model {}: '.format(i))\n    print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=classes))\n    print()\n    print('--------------------------------------------------------')","metadata":{"execution":{"iopub.status.busy":"2023-08-12T13:27:10.317386Z","iopub.execute_input":"2023-08-12T13:27:10.317785Z","iopub.status.idle":"2023-08-12T13:29:45.010101Z","shell.execute_reply.started":"2023-08-12T13:27:10.317753Z","shell.execute_reply":"2023-08-12T13:29:45.009036Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/50\n56/56 [==============================] - 19s 49ms/step - loss: 1.9620 - accuracy: 0.2275 - val_loss: 1.7083 - val_accuracy: 0.4172\nEpoch 2/50\n56/56 [==============================] - 1s 12ms/step - loss: 1.6268 - accuracy: 0.4067 - val_loss: 1.4705 - val_accuracy: 0.4629\nEpoch 3/50\n56/56 [==============================] - 1s 15ms/step - loss: 1.4778 - accuracy: 0.4873 - val_loss: 1.3170 - val_accuracy: 0.5404\nEpoch 4/50\n56/56 [==============================] - 1s 17ms/step - loss: 1.3447 - accuracy: 0.5451 - val_loss: 1.2523 - val_accuracy: 0.5689\nEpoch 5/50\n56/56 [==============================] - 1s 12ms/step - loss: 1.2797 - accuracy: 0.5806 - val_loss: 1.2227 - val_accuracy: 0.5662\nEpoch 6/50\n56/56 [==============================] - 1s 11ms/step - loss: 1.2295 - accuracy: 0.6004 - val_loss: 1.2518 - val_accuracy: 0.5550\nEpoch 7/50\n56/56 [==============================] - 1s 12ms/step - loss: 1.1906 - accuracy: 0.6043 - val_loss: 1.2628 - val_accuracy: 0.5543\nEpoch 8/50\n56/56 [==============================] - 1s 12ms/step - loss: 1.1360 - accuracy: 0.6271 - val_loss: 1.2145 - val_accuracy: 0.5788\nEpoch 9/50\n56/56 [==============================] - 1s 12ms/step - loss: 1.1035 - accuracy: 0.6410 - val_loss: 1.2373 - val_accuracy: 0.5669\nEpoch 10/50\n56/56 [==============================] - 1s 12ms/step - loss: 1.0780 - accuracy: 0.6491 - val_loss: 1.2343 - val_accuracy: 0.5795\nEpoch 11/50\n56/56 [==============================] - 1s 12ms/step - loss: 1.0272 - accuracy: 0.6623 - val_loss: 1.2043 - val_accuracy: 0.5927\nEpoch 12/50\n56/56 [==============================] - 1s 12ms/step - loss: 0.9905 - accuracy: 0.6722 - val_loss: 1.2230 - val_accuracy: 0.5887\nEpoch 13/50\n56/56 [==============================] - 1s 12ms/step - loss: 0.9657 - accuracy: 0.6896 - val_loss: 1.3002 - val_accuracy: 0.5854\nEpoch 14/50\n56/56 [==============================] - 1s 11ms/step - loss: 0.9263 - accuracy: 0.7016 - val_loss: 1.3310 - val_accuracy: 0.5848\nEpoch 15/50\n56/56 [==============================] - 1s 13ms/step - loss: 0.8884 - accuracy: 0.7093 - val_loss: 1.3093 - val_accuracy: 0.5788\nEpoch 16/50\n56/56 [==============================] - 1s 12ms/step - loss: 0.8776 - accuracy: 0.7153 - val_loss: 1.3314 - val_accuracy: 0.5921\nEpoch 17/50\n56/56 [==============================] - 1s 12ms/step - loss: 0.8352 - accuracy: 0.7296 - val_loss: 1.3331 - val_accuracy: 0.5841\nEpoch 18/50\n56/56 [==============================] - 1s 11ms/step - loss: 0.8200 - accuracy: 0.7348 - val_loss: 1.3656 - val_accuracy: 0.5927\nEpoch 19/50\n56/56 [==============================] - 1s 11ms/step - loss: 0.7473 - accuracy: 0.7577 - val_loss: 1.5058 - val_accuracy: 0.5854\nEpoch 20/50\n56/56 [==============================] - 1s 11ms/step - loss: 0.7363 - accuracy: 0.7628 - val_loss: 1.4743 - val_accuracy: 0.5868\nEpoch 21/50\n56/56 [==============================] - 1s 12ms/step - loss: 0.7324 - accuracy: 0.7639 - val_loss: 1.6233 - val_accuracy: 0.5801\n48/48 [==============================] - 2s 4ms/step\n--------------------------------------------------------\n\nCLassification report for model 1: \n              precision    recall  f1-score   support\n\n        none       0.55      0.87      0.67       229\n       anger       0.57      0.67      0.62       200\n         joy       0.43      0.42      0.42       205\n     sadness       0.53      0.35      0.42       185\n        love       0.75      0.60      0.66       193\n    sympathy       0.69      0.72      0.71       156\n    surprise       0.47      0.32      0.38       154\n        fear       0.88      0.78      0.82       188\n\n    accuracy                           0.60      1510\n   macro avg       0.61      0.59      0.59      1510\nweighted avg       0.61      0.60      0.59      1510\n\n\n--------------------------------------------------------\nEpoch 1/50\n56/56 [==============================] - 7s 25ms/step - loss: 1.8106 - accuracy: 0.3114 - val_loss: 1.5271 - val_accuracy: 0.4212\nEpoch 2/50\n56/56 [==============================] - 0s 8ms/step - loss: 1.4349 - accuracy: 0.4933 - val_loss: 1.3079 - val_accuracy: 0.5258\nEpoch 3/50\n56/56 [==============================] - 0s 8ms/step - loss: 1.2493 - accuracy: 0.5744 - val_loss: 1.2415 - val_accuracy: 0.5636\nEpoch 4/50\n56/56 [==============================] - 0s 8ms/step - loss: 1.1488 - accuracy: 0.6081 - val_loss: 1.2058 - val_accuracy: 0.5728\nEpoch 5/50\n56/56 [==============================] - 0s 8ms/step - loss: 1.0890 - accuracy: 0.6321 - val_loss: 1.2034 - val_accuracy: 0.5748\nEpoch 6/50\n56/56 [==============================] - 0s 8ms/step - loss: 1.0572 - accuracy: 0.6433 - val_loss: 1.1784 - val_accuracy: 0.5821\nEpoch 7/50\n56/56 [==============================] - 0s 8ms/step - loss: 1.0006 - accuracy: 0.6633 - val_loss: 1.1886 - val_accuracy: 0.5795\nEpoch 8/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.9589 - accuracy: 0.6761 - val_loss: 1.2117 - val_accuracy: 0.5881\nEpoch 9/50\n56/56 [==============================] - 0s 8ms/step - loss: 1.0262 - accuracy: 0.6571 - val_loss: 1.1770 - val_accuracy: 0.5868\nEpoch 10/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.9232 - accuracy: 0.6877 - val_loss: 1.2663 - val_accuracy: 0.5702\nEpoch 11/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.9256 - accuracy: 0.6832 - val_loss: 1.2450 - val_accuracy: 0.5735\nEpoch 12/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.8905 - accuracy: 0.6982 - val_loss: 1.2114 - val_accuracy: 0.5927\nEpoch 13/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.8242 - accuracy: 0.7246 - val_loss: 1.2763 - val_accuracy: 0.5821\nEpoch 14/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.8478 - accuracy: 0.7090 - val_loss: 1.2253 - val_accuracy: 0.5993\nEpoch 15/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.8010 - accuracy: 0.7320 - val_loss: 1.2565 - val_accuracy: 0.6040\nEpoch 16/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.7286 - accuracy: 0.7557 - val_loss: 1.2785 - val_accuracy: 0.5987\nEpoch 17/50\n56/56 [==============================] - 1s 9ms/step - loss: 0.7158 - accuracy: 0.7551 - val_loss: 1.4549 - val_accuracy: 0.5921\nEpoch 18/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.7115 - accuracy: 0.7578 - val_loss: 1.3442 - val_accuracy: 0.5894\nEpoch 19/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.6634 - accuracy: 0.7749 - val_loss: 1.4983 - val_accuracy: 0.5689\nEpoch 20/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.6798 - accuracy: 0.7683 - val_loss: 1.4125 - val_accuracy: 0.5927\nEpoch 21/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.5943 - accuracy: 0.8023 - val_loss: 1.4990 - val_accuracy: 0.5881\nEpoch 22/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.5306 - accuracy: 0.8231 - val_loss: 1.5949 - val_accuracy: 0.5616\nEpoch 23/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.5153 - accuracy: 0.8241 - val_loss: 1.6748 - val_accuracy: 0.5801\nEpoch 24/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.4674 - accuracy: 0.8450 - val_loss: 1.9352 - val_accuracy: 0.5523\nEpoch 25/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.5953 - accuracy: 0.8014 - val_loss: 1.6581 - val_accuracy: 0.5854\n48/48 [==============================] - 1s 3ms/step\n--------------------------------------------------------\n\nCLassification report for model 2: \n              precision    recall  f1-score   support\n\n        none       0.57      0.86      0.68       229\n       anger       0.52      0.67      0.58       200\n         joy       0.43      0.46      0.44       205\n     sadness       0.51      0.39      0.44       185\n        love       0.77      0.62      0.68       193\n    sympathy       0.62      0.69      0.65       156\n    surprise       0.56      0.18      0.27       154\n        fear       0.84      0.76      0.80       188\n\n    accuracy                           0.59      1510\n   macro avg       0.60      0.58      0.57      1510\nweighted avg       0.60      0.59      0.58      1510\n\n\n--------------------------------------------------------\nEpoch 1/50\n56/56 [==============================] - 4s 16ms/step - loss: 1.7610 - accuracy: 0.3901 - val_loss: 1.4710 - val_accuracy: 0.5318\nEpoch 2/50\n56/56 [==============================] - 0s 5ms/step - loss: 1.3677 - accuracy: 0.5463 - val_loss: 1.2810 - val_accuracy: 0.5563\nEpoch 3/50\n56/56 [==============================] - 0s 5ms/step - loss: 1.2183 - accuracy: 0.5817 - val_loss: 1.2171 - val_accuracy: 0.5762\nEpoch 4/50\n56/56 [==============================] - 0s 5ms/step - loss: 1.1555 - accuracy: 0.6037 - val_loss: 1.1851 - val_accuracy: 0.5748\nEpoch 5/50\n56/56 [==============================] - 0s 5ms/step - loss: 1.1227 - accuracy: 0.6155 - val_loss: 1.1587 - val_accuracy: 0.5834\nEpoch 6/50\n56/56 [==============================] - 0s 6ms/step - loss: 1.0935 - accuracy: 0.6254 - val_loss: 1.1472 - val_accuracy: 0.5861\nEpoch 7/50\n56/56 [==============================] - 0s 5ms/step - loss: 1.0600 - accuracy: 0.6344 - val_loss: 1.1438 - val_accuracy: 0.5940\nEpoch 8/50\n56/56 [==============================] - 0s 5ms/step - loss: 1.0455 - accuracy: 0.6430 - val_loss: 1.1475 - val_accuracy: 0.5841\nEpoch 9/50\n56/56 [==============================] - 0s 5ms/step - loss: 1.0353 - accuracy: 0.6450 - val_loss: 1.1342 - val_accuracy: 0.5861\nEpoch 10/50\n56/56 [==============================] - 0s 5ms/step - loss: 1.0149 - accuracy: 0.6487 - val_loss: 1.1317 - val_accuracy: 0.5934\nEpoch 11/50\n56/56 [==============================] - 0s 6ms/step - loss: 1.0065 - accuracy: 0.6541 - val_loss: 1.1269 - val_accuracy: 0.5940\nEpoch 12/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.9866 - accuracy: 0.6576 - val_loss: 1.1254 - val_accuracy: 0.5954\nEpoch 13/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.9751 - accuracy: 0.6616 - val_loss: 1.1285 - val_accuracy: 0.5934\nEpoch 14/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9755 - accuracy: 0.6634 - val_loss: 1.1313 - val_accuracy: 0.6073\nEpoch 15/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9680 - accuracy: 0.6615 - val_loss: 1.1236 - val_accuracy: 0.5987\nEpoch 16/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.9497 - accuracy: 0.6687 - val_loss: 1.1185 - val_accuracy: 0.6020\nEpoch 17/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9487 - accuracy: 0.6727 - val_loss: 1.1157 - val_accuracy: 0.6040\nEpoch 18/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.9399 - accuracy: 0.6764 - val_loss: 1.1188 - val_accuracy: 0.6026\nEpoch 19/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.9326 - accuracy: 0.6710 - val_loss: 1.1232 - val_accuracy: 0.5993\nEpoch 20/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.9242 - accuracy: 0.6775 - val_loss: 1.1117 - val_accuracy: 0.6060\nEpoch 21/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.9122 - accuracy: 0.6850 - val_loss: 1.1301 - val_accuracy: 0.6000\nEpoch 22/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.9115 - accuracy: 0.6748 - val_loss: 1.1146 - val_accuracy: 0.6060\nEpoch 23/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.9047 - accuracy: 0.6825 - val_loss: 1.1206 - val_accuracy: 0.6093\nEpoch 24/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.9053 - accuracy: 0.6774 - val_loss: 1.1241 - val_accuracy: 0.5980\nEpoch 25/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8821 - accuracy: 0.6846 - val_loss: 1.1171 - val_accuracy: 0.6106\nEpoch 26/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8817 - accuracy: 0.6860 - val_loss: 1.1227 - val_accuracy: 0.6073\nEpoch 27/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8743 - accuracy: 0.6933 - val_loss: 1.1241 - val_accuracy: 0.6079\nEpoch 28/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8763 - accuracy: 0.6893 - val_loss: 1.1198 - val_accuracy: 0.6040\nEpoch 29/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8744 - accuracy: 0.6903 - val_loss: 1.1251 - val_accuracy: 0.6079\nEpoch 30/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8657 - accuracy: 0.6937 - val_loss: 1.1175 - val_accuracy: 0.6099\nEpoch 31/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8526 - accuracy: 0.6982 - val_loss: 1.1253 - val_accuracy: 0.6073\nEpoch 32/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8412 - accuracy: 0.6998 - val_loss: 1.1211 - val_accuracy: 0.6113\nEpoch 33/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8389 - accuracy: 0.7038 - val_loss: 1.1226 - val_accuracy: 0.6113\nEpoch 34/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8372 - accuracy: 0.7031 - val_loss: 1.1181 - val_accuracy: 0.6119\nEpoch 35/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8315 - accuracy: 0.7096 - val_loss: 1.1234 - val_accuracy: 0.6199\nEpoch 36/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8155 - accuracy: 0.7140 - val_loss: 1.1417 - val_accuracy: 0.6086\nEpoch 37/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8076 - accuracy: 0.7136 - val_loss: 1.1192 - val_accuracy: 0.6126\nEpoch 38/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.8029 - accuracy: 0.7195 - val_loss: 1.1270 - val_accuracy: 0.6099\nEpoch 39/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.7930 - accuracy: 0.7194 - val_loss: 1.1271 - val_accuracy: 0.6086\nEpoch 40/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.7925 - accuracy: 0.7195 - val_loss: 1.1244 - val_accuracy: 0.6086\nEpoch 41/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.7744 - accuracy: 0.7256 - val_loss: 1.1262 - val_accuracy: 0.6106\nEpoch 42/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.7638 - accuracy: 0.7259 - val_loss: 1.1276 - val_accuracy: 0.6013\nEpoch 43/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.7665 - accuracy: 0.7295 - val_loss: 1.1321 - val_accuracy: 0.6205\nEpoch 44/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.7557 - accuracy: 0.7346 - val_loss: 1.1268 - val_accuracy: 0.6119\nEpoch 45/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.7581 - accuracy: 0.7334 - val_loss: 1.1363 - val_accuracy: 0.6179\nEpoch 46/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.7512 - accuracy: 0.7306 - val_loss: 1.1325 - val_accuracy: 0.6113\nEpoch 47/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.7394 - accuracy: 0.7337 - val_loss: 1.1455 - val_accuracy: 0.6066\nEpoch 48/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.7492 - accuracy: 0.7326 - val_loss: 1.1326 - val_accuracy: 0.6079\nEpoch 49/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.7266 - accuracy: 0.7402 - val_loss: 1.1315 - val_accuracy: 0.6066\nEpoch 50/50\n56/56 [==============================] - 0s 5ms/step - loss: 0.7109 - accuracy: 0.7431 - val_loss: 1.1394 - val_accuracy: 0.6126\n48/48 [==============================] - 0s 2ms/step\n--------------------------------------------------------\n\nCLassification report for model 3: \n              precision    recall  f1-score   support\n\n        none       0.62      0.83      0.71       229\n       anger       0.61      0.66      0.63       200\n         joy       0.51      0.48      0.50       205\n     sadness       0.53      0.36      0.43       185\n        love       0.69      0.67      0.68       193\n    sympathy       0.69      0.72      0.71       156\n    surprise       0.47      0.42      0.45       154\n        fear       0.82      0.79      0.81       188\n\n    accuracy                           0.62      1510\n   macro avg       0.62      0.62      0.61      1510\nweighted avg       0.62      0.62      0.62      1510\n\n\n--------------------------------------------------------\nEpoch 1/50\n56/56 [==============================] - 5s 18ms/step - loss: 1.7028 - accuracy: 0.4129 - val_loss: 1.4231 - val_accuracy: 0.5199\nEpoch 2/50\n56/56 [==============================] - 0s 6ms/step - loss: 1.3114 - accuracy: 0.5570 - val_loss: 1.2493 - val_accuracy: 0.5556\nEpoch 3/50\n56/56 [==============================] - 0s 7ms/step - loss: 1.1804 - accuracy: 0.5945 - val_loss: 1.1936 - val_accuracy: 0.5801\nEpoch 4/50\n56/56 [==============================] - 0s 6ms/step - loss: 1.1287 - accuracy: 0.6087 - val_loss: 1.1660 - val_accuracy: 0.5848\nEpoch 5/50\n56/56 [==============================] - 0s 7ms/step - loss: 1.0804 - accuracy: 0.6226 - val_loss: 1.1529 - val_accuracy: 0.5887\nEpoch 6/50\n56/56 [==============================] - 0s 6ms/step - loss: 1.0478 - accuracy: 0.6344 - val_loss: 1.1463 - val_accuracy: 0.5921\nEpoch 7/50\n56/56 [==============================] - 0s 6ms/step - loss: 1.0258 - accuracy: 0.6389 - val_loss: 1.1439 - val_accuracy: 0.5894\nEpoch 8/50\n56/56 [==============================] - 0s 7ms/step - loss: 1.0108 - accuracy: 0.6466 - val_loss: 1.1343 - val_accuracy: 0.5894\nEpoch 9/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9894 - accuracy: 0.6525 - val_loss: 1.1245 - val_accuracy: 0.6007\nEpoch 10/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9815 - accuracy: 0.6538 - val_loss: 1.1263 - val_accuracy: 0.5954\nEpoch 11/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9627 - accuracy: 0.6605 - val_loss: 1.1344 - val_accuracy: 0.5927\nEpoch 12/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9527 - accuracy: 0.6616 - val_loss: 1.1255 - val_accuracy: 0.6026\nEpoch 13/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.9472 - accuracy: 0.6640 - val_loss: 1.1281 - val_accuracy: 0.6000\nEpoch 14/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.9369 - accuracy: 0.6710 - val_loss: 1.1247 - val_accuracy: 0.5974\nEpoch 15/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9208 - accuracy: 0.6720 - val_loss: 1.1295 - val_accuracy: 0.5967\nEpoch 16/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9145 - accuracy: 0.6811 - val_loss: 1.1260 - val_accuracy: 0.5993\nEpoch 17/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.9111 - accuracy: 0.6771 - val_loss: 1.1318 - val_accuracy: 0.5954\nEpoch 18/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.8964 - accuracy: 0.6879 - val_loss: 1.1220 - val_accuracy: 0.6040\nEpoch 19/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8834 - accuracy: 0.6886 - val_loss: 1.1229 - val_accuracy: 0.6113\nEpoch 20/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8814 - accuracy: 0.6944 - val_loss: 1.1408 - val_accuracy: 0.5887\nEpoch 21/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8763 - accuracy: 0.6917 - val_loss: 1.1291 - val_accuracy: 0.6073\nEpoch 22/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8636 - accuracy: 0.6955 - val_loss: 1.1261 - val_accuracy: 0.6099\nEpoch 23/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8644 - accuracy: 0.6958 - val_loss: 1.1309 - val_accuracy: 0.6119\nEpoch 24/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.8478 - accuracy: 0.6960 - val_loss: 1.1238 - val_accuracy: 0.6166\nEpoch 25/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8365 - accuracy: 0.7079 - val_loss: 1.1475 - val_accuracy: 0.5993\nEpoch 26/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8375 - accuracy: 0.7060 - val_loss: 1.1384 - val_accuracy: 0.5954\nEpoch 27/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8236 - accuracy: 0.7053 - val_loss: 1.1314 - val_accuracy: 0.6033\nEpoch 28/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8181 - accuracy: 0.7083 - val_loss: 1.1540 - val_accuracy: 0.6106\nEpoch 29/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.7975 - accuracy: 0.7195 - val_loss: 1.1347 - val_accuracy: 0.6093\nEpoch 30/50\n56/56 [==============================] - 0s 9ms/step - loss: 0.7979 - accuracy: 0.7187 - val_loss: 1.1319 - val_accuracy: 0.6086\nEpoch 31/50\n56/56 [==============================] - 0s 9ms/step - loss: 0.7904 - accuracy: 0.7187 - val_loss: 1.1393 - val_accuracy: 0.6066\nEpoch 32/50\n56/56 [==============================] - 0s 8ms/step - loss: 0.7790 - accuracy: 0.7224 - val_loss: 1.1559 - val_accuracy: 0.5980\nEpoch 33/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.7708 - accuracy: 0.7209 - val_loss: 1.1366 - val_accuracy: 0.6146\nEpoch 34/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.7543 - accuracy: 0.7351 - val_loss: 1.1522 - val_accuracy: 0.6093\n48/48 [==============================] - 1s 2ms/step\n--------------------------------------------------------\n\nCLassification report for model 4: \n              precision    recall  f1-score   support\n\n        none       0.59      0.86      0.70       229\n       anger       0.65      0.62      0.63       200\n         joy       0.50      0.42      0.46       205\n     sadness       0.49      0.41      0.44       185\n        love       0.72      0.65      0.68       193\n    sympathy       0.69      0.72      0.71       156\n    surprise       0.47      0.41      0.44       154\n        fear       0.81      0.79      0.80       188\n\n    accuracy                           0.62      1510\n   macro avg       0.61      0.61      0.61      1510\nweighted avg       0.61      0.62      0.61      1510\n\n\n--------------------------------------------------------\nEpoch 1/50\n56/56 [==============================] - 6s 20ms/step - loss: 1.8184 - accuracy: 0.3251 - val_loss: 1.4638 - val_accuracy: 0.5219\nEpoch 2/50\n56/56 [==============================] - 0s 6ms/step - loss: 1.4187 - accuracy: 0.5022 - val_loss: 1.2454 - val_accuracy: 0.5616\nEpoch 3/50\n56/56 [==============================] - 0s 6ms/step - loss: 1.2627 - accuracy: 0.5614 - val_loss: 1.1995 - val_accuracy: 0.5735\nEpoch 4/50\n56/56 [==============================] - 0s 7ms/step - loss: 1.1970 - accuracy: 0.5825 - val_loss: 1.1666 - val_accuracy: 0.5808\nEpoch 5/50\n56/56 [==============================] - 0s 6ms/step - loss: 1.1451 - accuracy: 0.6006 - val_loss: 1.1522 - val_accuracy: 0.5788\nEpoch 6/50\n56/56 [==============================] - 0s 7ms/step - loss: 1.1035 - accuracy: 0.6190 - val_loss: 1.1394 - val_accuracy: 0.5881\nEpoch 7/50\n56/56 [==============================] - 0s 7ms/step - loss: 1.0772 - accuracy: 0.6278 - val_loss: 1.1669 - val_accuracy: 0.5934\nEpoch 8/50\n56/56 [==============================] - 0s 7ms/step - loss: 1.0549 - accuracy: 0.6353 - val_loss: 1.1247 - val_accuracy: 0.5894\nEpoch 9/50\n56/56 [==============================] - 0s 6ms/step - loss: 1.0448 - accuracy: 0.6359 - val_loss: 1.1413 - val_accuracy: 0.5887\nEpoch 10/50\n56/56 [==============================] - 0s 7ms/step - loss: 1.0282 - accuracy: 0.6480 - val_loss: 1.1170 - val_accuracy: 0.5974\nEpoch 11/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9873 - accuracy: 0.6534 - val_loss: 1.1300 - val_accuracy: 0.5993\nEpoch 12/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9951 - accuracy: 0.6564 - val_loss: 1.1299 - val_accuracy: 0.5954\nEpoch 13/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9586 - accuracy: 0.6674 - val_loss: 1.1251 - val_accuracy: 0.5974\nEpoch 14/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.9384 - accuracy: 0.6724 - val_loss: 1.1232 - val_accuracy: 0.6119\nEpoch 15/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.9509 - accuracy: 0.6676 - val_loss: 1.1247 - val_accuracy: 0.6026\nEpoch 16/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9270 - accuracy: 0.6686 - val_loss: 1.1456 - val_accuracy: 0.5921\nEpoch 17/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.9373 - accuracy: 0.6686 - val_loss: 1.1292 - val_accuracy: 0.5934\nEpoch 18/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.8913 - accuracy: 0.6843 - val_loss: 1.1237 - val_accuracy: 0.6033\nEpoch 19/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8853 - accuracy: 0.6889 - val_loss: 1.1206 - val_accuracy: 0.6026\nEpoch 20/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8650 - accuracy: 0.6925 - val_loss: 1.1209 - val_accuracy: 0.6046\nEpoch 21/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.8794 - accuracy: 0.6843 - val_loss: 1.1489 - val_accuracy: 0.5980\nEpoch 22/50\n56/56 [==============================] - 0s 6ms/step - loss: 0.8619 - accuracy: 0.6951 - val_loss: 1.1207 - val_accuracy: 0.6119\nEpoch 23/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.8438 - accuracy: 0.7036 - val_loss: 1.1430 - val_accuracy: 0.6073\nEpoch 24/50\n56/56 [==============================] - 0s 7ms/step - loss: 0.8288 - accuracy: 0.7011 - val_loss: 1.1387 - val_accuracy: 0.6079\n48/48 [==============================] - 1s 3ms/step\n--------------------------------------------------------\n\nCLassification report for model 5: \n              precision    recall  f1-score   support\n\n        none       0.57      0.86      0.68       229\n       anger       0.60      0.69      0.64       200\n         joy       0.47      0.49      0.48       205\n     sadness       0.55      0.36      0.43       185\n        love       0.70      0.68      0.69       193\n    sympathy       0.75      0.72      0.73       156\n    surprise       0.48      0.31      0.38       154\n        fear       0.87      0.77      0.82       188\n\n    accuracy                           0.62      1510\n   macro avg       0.62      0.61      0.61      1510\nweighted avg       0.62      0.62      0.61      1510\n\n\n--------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}