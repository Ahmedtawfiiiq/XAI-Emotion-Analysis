{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install gdown","metadata":{"id":"FtXnDFfR4_2b","outputId":"4e6de28f-8ba8-4e49-b0c3-21acba14110f","execution":{"iopub.status.busy":"2023-08-11T13:31:32.083158Z","iopub.execute_input":"2023-08-11T13:31:32.084013Z","iopub.status.idle":"2023-08-11T13:31:46.153040Z","shell.execute_reply.started":"2023-08-11T13:31:32.083975Z","shell.execute_reply":"2023-08-11T13:31:46.151915Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.65.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"!gdown \"1n6IHWly66qSJfxrDSaIBcqm05jo-v6mt\"\n!gdown \"1zToBjksCyT4DYAZ-0Oqj52nEXk0aqtdm\"\n!gdown \"1wKZjFyWcfsTveGpuRwXHqmfFW8Zu8cIe\"\n!gdown \"10S8tYhh1jd5VyQD7Rbw2QVBXIfw3hd1H\"\n!gdown \"1Fs0PTy_xPsoX5bg4QTCrX6JAaQCHRzis\"\n!gdown \"1JLa-ELhUskQINi0syf3YJWBX8jcCXdn4\"","metadata":{"execution":{"iopub.status.busy":"2023-08-11T13:31:46.155363Z","iopub.execute_input":"2023-08-11T13:31:46.156661Z","iopub.status.idle":"2023-08-11T13:32:53.418754Z","shell.execute_reply.started":"2023-08-11T13:31:46.156630Z","shell.execute_reply":"2023-08-11T13:32:53.417542Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1n6IHWly66qSJfxrDSaIBcqm05jo-v6mt\nTo: /kaggle/working/rs_train_embeddings.pkl\n100%|██████████████████████████████████████| 49.5M/49.5M [00:01<00:00, 44.0MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1zToBjksCyT4DYAZ-0Oqj52nEXk0aqtdm\nTo: /kaggle/working/rs_test_embeddings.pkl\n100%|██████████████████████████████████████| 12.4M/12.4M [00:00<00:00, 41.7MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1wKZjFyWcfsTveGpuRwXHqmfFW8Zu8cIe\nTo: /kaggle/working/ls_train_embeddings.pkl\n100%|██████████████████████████████████████| 49.5M/49.5M [00:01<00:00, 32.5MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=10S8tYhh1jd5VyQD7Rbw2QVBXIfw3hd1H\nTo: /kaggle/working/ls_test_embeddings.pkl\n100%|██████████████████████████████████████| 12.4M/12.4M [00:00<00:00, 29.3MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1Fs0PTy_xPsoX5bg4QTCrX6JAaQCHRzis\nTo: /kaggle/working/train.pkl\n100%|███████████████████████████████████████| 4.09M/4.09M [00:00<00:00, 197MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1JLa-ELhUskQINi0syf3YJWBX8jcCXdn4\nTo: /kaggle/working/test.pkl\n100%|███████████████████████████████████████| 1.02M/1.02M [00:00<00:00, 116MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nimport string\nimport re\nimport pickle\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.isri import ISRIStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import confusion_matrix,accuracy_score, classification_report\nfrom sklearn.svm import SVC\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.layers import MaxPooling1D\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import backend as K\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nimport seaborn as sns\nimport torch\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing import sequence\nfrom collections import OrderedDict\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"id":"cLmXB__I1uOg","execution":{"iopub.status.busy":"2023-08-11T13:32:53.421524Z","iopub.execute_input":"2023-08-11T13:32:53.422246Z","iopub.status.idle":"2023-08-11T13:33:06.137032Z","shell.execute_reply.started":"2023-08-11T13:32:53.422205Z","shell.execute_reply":"2023-08-11T13:33:06.136063Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"label_to_class = {\n    0: 'none',\n    1: 'anger',\n    2: 'joy',\n    3: 'sadness',\n    4: 'love',\n    5: 'sympathy',\n    6: 'surprise',\n    7: 'fear'\n}\nclasses = ['none', 'anger', 'joy', 'sadness', 'love', 'sympathy', 'surprise', 'fear']","metadata":{"execution":{"iopub.status.busy":"2023-08-11T13:33:06.139580Z","iopub.execute_input":"2023-08-11T13:33:06.140315Z","iopub.status.idle":"2023-08-11T13:33:06.145695Z","shell.execute_reply.started":"2023-08-11T13:33:06.140279Z","shell.execute_reply":"2023-08-11T13:33:06.144707Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/train.pkl', 'rb') as f:\n    train = pickle.load(f)\n\nwith open('/kaggle/working/test.pkl', 'rb') as f:\n    test = pickle.load(f)\n\nwith open('/kaggle/working/rs_train_embeddings.pkl', 'rb') as f:\n    rs_train_embeddings = pickle.load(f)\n    \nwith open('/kaggle/working/rs_test_embeddings.pkl', 'rb') as f:\n    rs_test_embeddings = pickle.load(f)\n    \nwith open('/kaggle/working/ls_train_embeddings.pkl', 'rb') as f:\n    ls_train_embeddings = pickle.load(f)\n    \nwith open('/kaggle/working/ls_test_embeddings.pkl', 'rb') as f:\n    ls_test_embeddings = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-08-11T13:33:06.147049Z","iopub.execute_input":"2023-08-11T13:33:06.147665Z","iopub.status.idle":"2023-08-11T13:33:06.260439Z","shell.execute_reply.started":"2023-08-11T13:33:06.147630Z","shell.execute_reply":"2023-08-11T13:33:06.259412Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_train = rs_train_embeddings.reshape(rs_train_embeddings.shape[0], 1, rs_train_embeddings.shape[1]) # reshape input to allow for GRU\nX_test = rs_test_embeddings.reshape(rs_test_embeddings.shape[0], 1, rs_test_embeddings.shape[1]) # reshape input to allow for GRU","metadata":{"execution":{"iopub.status.busy":"2023-08-11T13:33:06.261946Z","iopub.execute_input":"2023-08-11T13:33:06.262286Z","iopub.status.idle":"2023-08-11T13:33:06.270042Z","shell.execute_reply.started":"2023-08-11T13:33:06.262250Z","shell.execute_reply":"2023-08-11T13:33:06.269052Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"encoder = OneHotEncoder()\n\ny_train = encoder.fit_transform(train['label'].values.reshape(-1,1)).toarray()\ny_test = encoder.transform(test['label'].values.reshape(-1,1)).toarray()","metadata":{"execution":{"iopub.status.busy":"2023-08-11T13:33:06.271555Z","iopub.execute_input":"2023-08-11T13:33:06.271989Z","iopub.status.idle":"2023-08-11T13:33:06.288767Z","shell.execute_reply.started":"2023-08-11T13:33:06.271957Z","shell.execute_reply":"2023-08-11T13:33:06.287713Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 128\nEPOCHS = 50\nEMBED_SIZE = 300\nLEARNING_RATE =  0.001\n\nearly_stopping_monitor = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0,\n    patience=10,\n    verbose=0,\n    mode='max',\n    baseline=None,\n    restore_best_weights=True)","metadata":{"id":"aNV13COwKUd5","execution":{"iopub.status.busy":"2023-08-11T13:33:06.290053Z","iopub.execute_input":"2023-08-11T13:33:06.290452Z","iopub.status.idle":"2023-08-11T13:33:06.296583Z","shell.execute_reply.started":"2023-08-11T13:33:06.290409Z","shell.execute_reply":"2023-08-11T13:33:06.295599Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def create_gru_model(model_type):\n    model = Sequential()\n#     model.add(Embedding(VOCAB_SIZE, EMBED_SIZE, input_length=max_length, trainable=True))\n    if model_type==1:\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)))\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512, return_sequences=True)))\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=False)))\n        model.add(Dropout(0.5))\n        model.add(Dense(128, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(64, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(8, activation='softmax'))\n    elif model_type==2:\n        model.add(tf.keras.layers.GRU(512, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n        model.add(tf.keras.layers.GRU(256, return_sequences=True))\n        model.add(tf.keras.layers.GRU(128, return_sequences=False))\n        model.add(Dense(128, activation='relu'))\n        model.add(Dropout(0.2))\n        model.add(Dense(64, activation='relu'))\n        model.add(Dropout(0.2))\n        model.add(Dense(8, activation='softmax'))\n    elif model_type==3:\n        model.add(tf.keras.layers.GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))\n        model.add(Dropout(0.5))\n        model.add(Flatten())\n        model.add(Dense(8, activation='softmax'))\n    elif model_type==4:\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False)))\n        model.add(Dropout(0.5))\n        model.add(Flatten())\n        model.add(Dense(8, activation='softmax'))\n    elif model_type==5:\n        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False)))\n        model.add(Dropout(0.5))\n        model.add(Dense(128, activation='relu'))\n        model.add(Dropout(0.5))\n        model.add(Dense(8, activation='softmax'))\n    \n    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n    # model.summary()\n\n    history = model.fit(X_train, np.asarray(y_train), validation_data=(X_test, np.asarray(y_test)), batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[early_stopping_monitor])\n    return model, history","metadata":{"execution":{"iopub.status.busy":"2023-08-11T13:33:06.298179Z","iopub.execute_input":"2023-08-11T13:33:06.298867Z","iopub.status.idle":"2023-08-11T13:33:06.318185Z","shell.execute_reply.started":"2023-08-11T13:33:06.298833Z","shell.execute_reply":"2023-08-11T13:33:06.317276Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for i in range(1,6):\n    model, _ = create_gru_model(i)\n    predictions = model.predict(X_test)\n    print('--------------------------------------------------------')\n    print()\n    print('CLassification report for model {}: '.format(i))\n    print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=classes))\n    print()\n    print('--------------------------------------------------------')","metadata":{"execution":{"iopub.status.busy":"2023-08-11T13:33:06.321629Z","iopub.execute_input":"2023-08-11T13:33:06.322538Z","iopub.status.idle":"2023-08-11T13:35:09.164011Z","shell.execute_reply.started":"2023-08-11T13:33:06.322506Z","shell.execute_reply":"2023-08-11T13:35:09.162924Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/50\n63/63 [==============================] - 19s 42ms/step - loss: 1.8096 - accuracy: 0.3197 - val_loss: 1.3815 - val_accuracy: 0.5092\nEpoch 2/50\n63/63 [==============================] - 1s 17ms/step - loss: 1.4189 - accuracy: 0.5068 - val_loss: 1.1992 - val_accuracy: 0.6026\nEpoch 3/50\n63/63 [==============================] - 1s 14ms/step - loss: 1.2973 - accuracy: 0.5638 - val_loss: 1.1112 - val_accuracy: 0.6334\nEpoch 4/50\n63/63 [==============================] - 1s 12ms/step - loss: 1.1842 - accuracy: 0.6133 - val_loss: 1.1438 - val_accuracy: 0.6031\nEpoch 5/50\n63/63 [==============================] - 1s 13ms/step - loss: 1.1086 - accuracy: 0.6380 - val_loss: 1.0916 - val_accuracy: 0.6384\nEpoch 6/50\n63/63 [==============================] - 1s 13ms/step - loss: 1.0391 - accuracy: 0.6701 - val_loss: 1.1786 - val_accuracy: 0.6190\nEpoch 7/50\n63/63 [==============================] - 1s 12ms/step - loss: 1.0001 - accuracy: 0.6808 - val_loss: 1.1030 - val_accuracy: 0.6329\nEpoch 8/50\n63/63 [==============================] - 1s 12ms/step - loss: 0.9528 - accuracy: 0.6935 - val_loss: 1.0968 - val_accuracy: 0.6533\nEpoch 9/50\n63/63 [==============================] - 1s 13ms/step - loss: 0.8772 - accuracy: 0.7212 - val_loss: 1.1445 - val_accuracy: 0.6244\nEpoch 10/50\n63/63 [==============================] - 1s 13ms/step - loss: 0.7824 - accuracy: 0.7547 - val_loss: 1.3297 - val_accuracy: 0.6080\nEpoch 11/50\n63/63 [==============================] - 1s 12ms/step - loss: 0.7730 - accuracy: 0.7542 - val_loss: 1.2145 - val_accuracy: 0.6364\nEpoch 12/50\n63/63 [==============================] - 1s 11ms/step - loss: 0.7372 - accuracy: 0.7696 - val_loss: 1.3402 - val_accuracy: 0.6026\nEpoch 13/50\n63/63 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.7778 - val_loss: 1.3821 - val_accuracy: 0.6319\nEpoch 14/50\n63/63 [==============================] - 1s 12ms/step - loss: 0.5915 - accuracy: 0.8153 - val_loss: 1.4134 - val_accuracy: 0.6359\nEpoch 15/50\n63/63 [==============================] - 1s 12ms/step - loss: 0.5525 - accuracy: 0.8258 - val_loss: 1.5150 - val_accuracy: 0.6299\nEpoch 16/50\n63/63 [==============================] - 1s 13ms/step - loss: 0.5156 - accuracy: 0.8354 - val_loss: 1.6141 - val_accuracy: 0.6210\nEpoch 17/50\n63/63 [==============================] - 1s 12ms/step - loss: 0.4850 - accuracy: 0.8462 - val_loss: 1.8269 - val_accuracy: 0.6170\nEpoch 18/50\n63/63 [==============================] - 1s 12ms/step - loss: 0.4898 - accuracy: 0.8454 - val_loss: 1.7190 - val_accuracy: 0.6418\n63/63 [==============================] - 2s 4ms/step\n--------------------------------------------------------\n\nCLassification report for model 1: \n              precision    recall  f1-score   support\n\n        none       0.62      0.91      0.74       307\n       anger       0.68      0.65      0.66       276\n         joy       0.50      0.50      0.50       268\n     sadness       0.59      0.37      0.45       258\n        love       0.70      0.74      0.72       250\n    sympathy       0.64      0.80      0.71       194\n    surprise       0.55      0.30      0.39       201\n        fear       0.90      0.88      0.89       259\n\n    accuracy                           0.65      2013\n   macro avg       0.65      0.64      0.63      2013\nweighted avg       0.65      0.65      0.64      2013\n\n\n--------------------------------------------------------\nEpoch 1/50\n63/63 [==============================] - 8s 31ms/step - loss: 1.5050 - accuracy: 0.4731 - val_loss: 1.1564 - val_accuracy: 0.5897\nEpoch 2/50\n63/63 [==============================] - 1s 11ms/step - loss: 1.1139 - accuracy: 0.6203 - val_loss: 1.0539 - val_accuracy: 0.6443\nEpoch 3/50\n63/63 [==============================] - 1s 13ms/step - loss: 0.9984 - accuracy: 0.6678 - val_loss: 1.0394 - val_accuracy: 0.6533\nEpoch 4/50\n63/63 [==============================] - 1s 8ms/step - loss: 0.9144 - accuracy: 0.6929 - val_loss: 1.0117 - val_accuracy: 0.6607\nEpoch 5/50\n63/63 [==============================] - 0s 8ms/step - loss: 0.8461 - accuracy: 0.7135 - val_loss: 1.0541 - val_accuracy: 0.6384\nEpoch 6/50\n63/63 [==============================] - 1s 11ms/step - loss: 0.7634 - accuracy: 0.7439 - val_loss: 1.1052 - val_accuracy: 0.6418\nEpoch 7/50\n63/63 [==============================] - 1s 10ms/step - loss: 0.7031 - accuracy: 0.7611 - val_loss: 1.2247 - val_accuracy: 0.6195\nEpoch 8/50\n63/63 [==============================] - 1s 10ms/step - loss: 0.6364 - accuracy: 0.7880 - val_loss: 1.1563 - val_accuracy: 0.6314\nEpoch 9/50\n63/63 [==============================] - 1s 9ms/step - loss: 0.5454 - accuracy: 0.8195 - val_loss: 1.3379 - val_accuracy: 0.6195\nEpoch 10/50\n63/63 [==============================] - 1s 8ms/step - loss: 0.4941 - accuracy: 0.8359 - val_loss: 1.3298 - val_accuracy: 0.6364\nEpoch 11/50\n63/63 [==============================] - 1s 8ms/step - loss: 0.4536 - accuracy: 0.8458 - val_loss: 1.3961 - val_accuracy: 0.6100\nEpoch 12/50\n63/63 [==============================] - 0s 8ms/step - loss: 0.4006 - accuracy: 0.8628 - val_loss: 1.6250 - val_accuracy: 0.5951\nEpoch 13/50\n63/63 [==============================] - 1s 8ms/step - loss: 0.3737 - accuracy: 0.8718 - val_loss: 1.5177 - val_accuracy: 0.6056\nEpoch 14/50\n63/63 [==============================] - 1s 9ms/step - loss: 0.3248 - accuracy: 0.8937 - val_loss: 1.5498 - val_accuracy: 0.6120\n63/63 [==============================] - 1s 3ms/step\n--------------------------------------------------------\n\nCLassification report for model 2: \n              precision    recall  f1-score   support\n\n        none       0.64      0.90      0.75       307\n       anger       0.56      0.75      0.64       276\n         joy       0.57      0.50      0.53       268\n     sadness       0.53      0.49      0.51       258\n        love       0.70      0.71      0.70       250\n    sympathy       0.77      0.69      0.72       194\n    surprise       0.65      0.25      0.37       201\n        fear       0.97      0.86      0.91       259\n\n    accuracy                           0.66      2013\n   macro avg       0.67      0.64      0.64      2013\nweighted avg       0.67      0.66      0.65      2013\n\n\n--------------------------------------------------------\nEpoch 1/50\n63/63 [==============================] - 3s 12ms/step - loss: 1.5464 - accuracy: 0.4568 - val_loss: 1.1982 - val_accuracy: 0.5877\nEpoch 2/50\n63/63 [==============================] - 0s 5ms/step - loss: 1.1984 - accuracy: 0.5859 - val_loss: 1.1036 - val_accuracy: 0.6299\nEpoch 3/50\n63/63 [==============================] - 0s 5ms/step - loss: 1.0933 - accuracy: 0.6239 - val_loss: 1.0655 - val_accuracy: 0.6289\nEpoch 4/50\n63/63 [==============================] - 0s 5ms/step - loss: 1.0209 - accuracy: 0.6478 - val_loss: 1.0330 - val_accuracy: 0.6453\nEpoch 5/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.9707 - accuracy: 0.6652 - val_loss: 1.0233 - val_accuracy: 0.6503\nEpoch 6/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.9268 - accuracy: 0.6792 - val_loss: 1.0196 - val_accuracy: 0.6557\nEpoch 7/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.9019 - accuracy: 0.6903 - val_loss: 1.0111 - val_accuracy: 0.6423\nEpoch 8/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.8524 - accuracy: 0.7042 - val_loss: 1.0137 - val_accuracy: 0.6523\nEpoch 9/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.8532 - accuracy: 0.7017 - val_loss: 1.0132 - val_accuracy: 0.6453\nEpoch 10/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.8122 - accuracy: 0.7158 - val_loss: 1.0089 - val_accuracy: 0.6602\nEpoch 11/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.7763 - accuracy: 0.7281 - val_loss: 0.9999 - val_accuracy: 0.6567\nEpoch 12/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.7554 - accuracy: 0.7382 - val_loss: 1.0032 - val_accuracy: 0.6602\nEpoch 13/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.7153 - accuracy: 0.7498 - val_loss: 0.9963 - val_accuracy: 0.6622\nEpoch 14/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.6924 - accuracy: 0.7587 - val_loss: 1.0081 - val_accuracy: 0.6567\nEpoch 15/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.6647 - accuracy: 0.7653 - val_loss: 1.0041 - val_accuracy: 0.6607\nEpoch 16/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.6490 - accuracy: 0.7751 - val_loss: 1.0161 - val_accuracy: 0.6597\nEpoch 17/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.6275 - accuracy: 0.7765 - val_loss: 1.0206 - val_accuracy: 0.6642\nEpoch 18/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.7855 - val_loss: 1.0312 - val_accuracy: 0.6562\nEpoch 19/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.5657 - accuracy: 0.8068 - val_loss: 1.0409 - val_accuracy: 0.6547\nEpoch 20/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.5570 - accuracy: 0.8040 - val_loss: 1.0285 - val_accuracy: 0.6612\nEpoch 21/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.8121 - val_loss: 1.0339 - val_accuracy: 0.6642\nEpoch 22/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.5261 - accuracy: 0.8194 - val_loss: 1.0516 - val_accuracy: 0.6592\nEpoch 23/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.5137 - accuracy: 0.8199 - val_loss: 1.0833 - val_accuracy: 0.6384\nEpoch 24/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.8290 - val_loss: 1.0769 - val_accuracy: 0.6463\nEpoch 25/50\n63/63 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.8335 - val_loss: 1.1124 - val_accuracy: 0.6607\nEpoch 26/50\n63/63 [==============================] - 0s 8ms/step - loss: 0.4593 - accuracy: 0.8423 - val_loss: 1.1049 - val_accuracy: 0.6468\nEpoch 27/50\n63/63 [==============================] - 0s 8ms/step - loss: 0.4349 - accuracy: 0.8479 - val_loss: 1.0988 - val_accuracy: 0.6528\n63/63 [==============================] - 1s 2ms/step\n--------------------------------------------------------\n\nCLassification report for model 3: \n              precision    recall  f1-score   support\n\n        none       0.65      0.86      0.74       307\n       anger       0.61      0.70      0.65       276\n         joy       0.53      0.53      0.53       268\n     sadness       0.59      0.47      0.52       258\n        love       0.77      0.67      0.72       250\n    sympathy       0.71      0.74      0.73       194\n    surprise       0.53      0.35      0.42       201\n        fear       0.86      0.91      0.89       259\n\n    accuracy                           0.66      2013\n   macro avg       0.66      0.65      0.65      2013\nweighted avg       0.66      0.66      0.66      2013\n\n\n--------------------------------------------------------\nEpoch 1/50\n63/63 [==============================] - 6s 18ms/step - loss: 1.5000 - accuracy: 0.4732 - val_loss: 1.1443 - val_accuracy: 0.5857\nEpoch 2/50\n63/63 [==============================] - 0s 6ms/step - loss: 1.1412 - accuracy: 0.6056 - val_loss: 1.0821 - val_accuracy: 0.6329\nEpoch 3/50\n63/63 [==============================] - 0s 6ms/step - loss: 1.0486 - accuracy: 0.6350 - val_loss: 1.0497 - val_accuracy: 0.6369\nEpoch 4/50\n63/63 [==============================] - 0s 6ms/step - loss: 0.9861 - accuracy: 0.6603 - val_loss: 1.0259 - val_accuracy: 0.6518\nEpoch 5/50\n63/63 [==============================] - 0s 6ms/step - loss: 0.9302 - accuracy: 0.6730 - val_loss: 1.0085 - val_accuracy: 0.6483\nEpoch 6/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.8805 - accuracy: 0.6932 - val_loss: 1.0052 - val_accuracy: 0.6448\nEpoch 7/50\n63/63 [==============================] - 0s 6ms/step - loss: 0.8374 - accuracy: 0.7113 - val_loss: 1.0025 - val_accuracy: 0.6577\nEpoch 8/50\n63/63 [==============================] - 0s 6ms/step - loss: 0.7994 - accuracy: 0.7165 - val_loss: 1.0064 - val_accuracy: 0.6433\nEpoch 9/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.7601 - accuracy: 0.7312 - val_loss: 1.0027 - val_accuracy: 0.6557\nEpoch 10/50\n63/63 [==============================] - 0s 6ms/step - loss: 0.7306 - accuracy: 0.7409 - val_loss: 1.0247 - val_accuracy: 0.6488\nEpoch 11/50\n63/63 [==============================] - 0s 6ms/step - loss: 0.7004 - accuracy: 0.7536 - val_loss: 1.0321 - val_accuracy: 0.6528\nEpoch 12/50\n63/63 [==============================] - 0s 6ms/step - loss: 0.6571 - accuracy: 0.7716 - val_loss: 1.0243 - val_accuracy: 0.6493\nEpoch 13/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.6215 - accuracy: 0.7791 - val_loss: 1.0318 - val_accuracy: 0.6498\nEpoch 14/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.5947 - accuracy: 0.7866 - val_loss: 1.0361 - val_accuracy: 0.6542\nEpoch 15/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.5668 - accuracy: 0.8015 - val_loss: 1.0712 - val_accuracy: 0.6572\nEpoch 16/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.5312 - accuracy: 0.8192 - val_loss: 1.0647 - val_accuracy: 0.6463\nEpoch 17/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.4941 - accuracy: 0.8306 - val_loss: 1.0718 - val_accuracy: 0.6483\n63/63 [==============================] - 1s 2ms/step\n--------------------------------------------------------\n\nCLassification report for model 4: \n              precision    recall  f1-score   support\n\n        none       0.62      0.92      0.74       307\n       anger       0.64      0.70      0.67       276\n         joy       0.53      0.53      0.53       268\n     sadness       0.57      0.42      0.49       258\n        love       0.76      0.68      0.72       250\n    sympathy       0.69      0.75      0.72       194\n    surprise       0.54      0.30      0.39       201\n        fear       0.89      0.84      0.87       259\n\n    accuracy                           0.66      2013\n   macro avg       0.65      0.64      0.64      2013\nweighted avg       0.66      0.66      0.65      2013\n\n\n--------------------------------------------------------\nEpoch 1/50\n63/63 [==============================] - 6s 18ms/step - loss: 1.7166 - accuracy: 0.3855 - val_loss: 1.2700 - val_accuracy: 0.5663\nEpoch 2/50\n63/63 [==============================] - 0s 7ms/step - loss: 1.3445 - accuracy: 0.5330 - val_loss: 1.1427 - val_accuracy: 0.6205\nEpoch 3/50\n63/63 [==============================] - 0s 7ms/step - loss: 1.2164 - accuracy: 0.5827 - val_loss: 1.1040 - val_accuracy: 0.6185\nEpoch 4/50\n63/63 [==============================] - 0s 7ms/step - loss: 1.1610 - accuracy: 0.5969 - val_loss: 1.0555 - val_accuracy: 0.6433\nEpoch 5/50\n63/63 [==============================] - 0s 7ms/step - loss: 1.1201 - accuracy: 0.6171 - val_loss: 1.0444 - val_accuracy: 0.6388\nEpoch 6/50\n63/63 [==============================] - 0s 7ms/step - loss: 1.0600 - accuracy: 0.6314 - val_loss: 1.0312 - val_accuracy: 0.6523\nEpoch 7/50\n63/63 [==============================] - 0s 6ms/step - loss: 1.0186 - accuracy: 0.6483 - val_loss: 1.0170 - val_accuracy: 0.6463\nEpoch 8/50\n63/63 [==============================] - 0s 7ms/step - loss: 1.0011 - accuracy: 0.6521 - val_loss: 1.0053 - val_accuracy: 0.6542\nEpoch 9/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.9591 - accuracy: 0.6647 - val_loss: 1.0053 - val_accuracy: 0.6503\nEpoch 10/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.9292 - accuracy: 0.6757 - val_loss: 1.0158 - val_accuracy: 0.6493\nEpoch 11/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.9033 - accuracy: 0.6802 - val_loss: 1.0142 - val_accuracy: 0.6448\nEpoch 12/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.8793 - accuracy: 0.6932 - val_loss: 1.0005 - val_accuracy: 0.6582\nEpoch 13/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.8636 - accuracy: 0.6956 - val_loss: 1.0239 - val_accuracy: 0.6542\nEpoch 14/50\n63/63 [==============================] - 0s 6ms/step - loss: 0.8305 - accuracy: 0.7094 - val_loss: 1.0052 - val_accuracy: 0.6597\nEpoch 15/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.8052 - accuracy: 0.7166 - val_loss: 1.0314 - val_accuracy: 0.6483\nEpoch 16/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.7959 - accuracy: 0.7163 - val_loss: 1.0060 - val_accuracy: 0.6647\nEpoch 17/50\n63/63 [==============================] - 0s 6ms/step - loss: 0.7634 - accuracy: 0.7289 - val_loss: 1.0280 - val_accuracy: 0.6577\nEpoch 18/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.7330 - accuracy: 0.7378 - val_loss: 1.0275 - val_accuracy: 0.6652\nEpoch 19/50\n63/63 [==============================] - 0s 6ms/step - loss: 0.7330 - accuracy: 0.7418 - val_loss: 1.0480 - val_accuracy: 0.6602\nEpoch 20/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.7075 - accuracy: 0.7488 - val_loss: 1.0525 - val_accuracy: 0.6508\nEpoch 21/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.6980 - accuracy: 0.7481 - val_loss: 1.0674 - val_accuracy: 0.6682\nEpoch 22/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.6583 - accuracy: 0.7627 - val_loss: 1.0728 - val_accuracy: 0.6582\nEpoch 23/50\n63/63 [==============================] - 0s 6ms/step - loss: 0.6289 - accuracy: 0.7776 - val_loss: 1.0796 - val_accuracy: 0.6642\nEpoch 24/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.6171 - accuracy: 0.7797 - val_loss: 1.1040 - val_accuracy: 0.6528\nEpoch 25/50\n63/63 [==============================] - 0s 8ms/step - loss: 0.6041 - accuracy: 0.7807 - val_loss: 1.1308 - val_accuracy: 0.6463\nEpoch 26/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.5758 - accuracy: 0.7966 - val_loss: 1.1471 - val_accuracy: 0.6567\nEpoch 27/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.5645 - accuracy: 0.7982 - val_loss: 1.1434 - val_accuracy: 0.6577\nEpoch 28/50\n63/63 [==============================] - 1s 9ms/step - loss: 0.5381 - accuracy: 0.8084 - val_loss: 1.1728 - val_accuracy: 0.6448\nEpoch 29/50\n63/63 [==============================] - 1s 10ms/step - loss: 0.5297 - accuracy: 0.8125 - val_loss: 1.1951 - val_accuracy: 0.6503\nEpoch 30/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.5112 - accuracy: 0.8191 - val_loss: 1.2091 - val_accuracy: 0.6423\nEpoch 31/50\n63/63 [==============================] - 0s 7ms/step - loss: 0.4850 - accuracy: 0.8295 - val_loss: 1.2342 - val_accuracy: 0.6513\n63/63 [==============================] - 1s 2ms/step\n--------------------------------------------------------\n\nCLassification report for model 5: \n              precision    recall  f1-score   support\n\n        none       0.61      0.94      0.74       307\n       anger       0.58      0.78      0.66       276\n         joy       0.61      0.41      0.49       268\n     sadness       0.62      0.41      0.49       258\n        love       0.74      0.69      0.71       250\n    sympathy       0.74      0.75      0.75       194\n    surprise       0.56      0.37      0.45       201\n        fear       0.90      0.90      0.90       259\n\n    accuracy                           0.67      2013\n   macro avg       0.67      0.66      0.65      2013\nweighted avg       0.67      0.67      0.65      2013\n\n\n--------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}