{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install gdown\n!pip install git+https://github.com/yidinghao/interpreting-nlp","metadata":{"id":"FtXnDFfR4_2b","outputId":"4e6de28f-8ba8-4e49-b0c3-21acba14110f","execution":{"iopub.status.busy":"2023-08-12T18:33:22.105705Z","iopub.execute_input":"2023-08-12T18:33:22.106941Z","iopub.status.idle":"2023-08-12T18:33:52.959670Z","shell.execute_reply.started":"2023-08-12T18:33:22.106903Z","shell.execute_reply":"2023-08-12T18:33:52.958344Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.65.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\nNote: you may need to restart the kernel to use updated packages.\nCollecting git+https://github.com/yidinghao/interpreting-nlp\n  Cloning https://github.com/yidinghao/interpreting-nlp to /tmp/pip-req-build-9h077v4y\n  Running command git clone --filter=blob:none --quiet https://github.com/yidinghao/interpreting-nlp /tmp/pip-req-build-9h077v4y\n  Resolved https://github.com/yidinghao/interpreting-nlp to commit b6bf81e2e52970ffe4db32cade8c9c3d48d1cd3b\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: interpret-nlp\n  Building wheel for interpret-nlp (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for interpret-nlp: filename=interpret_nlp-0.1-py3-none-any.whl size=14714 sha256=2d091bae9460de4be04d2dbc201b0e5d9367f0fa387ec4bcc21de78bde34f0ed\n  Stored in directory: /tmp/pip-ephem-wheel-cache-cs_1khpi/wheels/c0/d4/0f/9d21571e687d4e3dcf61b6538dedff103fdc48bad18ca6c357\nSuccessfully built interpret-nlp\nInstalling collected packages: interpret-nlp\nSuccessfully installed interpret-nlp-0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"train = '1HqceFWkRXwEqgPcuAtACFVvHhKO_TGG6'\nval = '1XEsLOUFJTnCGcitk4IUS23H6IlzCzwqZ'\ntest = '1Lu5ItQvj2iGRqMXJ-bovQkys0eilR9HZ'\n\ntrain_embeddings_per_word = '1-0Bb3pLy_EhEggA-VsOh8TIS92VbmmxV'\nval_embeddings_per_word = '1-0WpebJIz9q2PZ_Baf51ZUsiBx9pWVJP'\ntest_embeddings_per_word = '1pi6DGhZ7AoGzC3cqP-ET5Qvkc3HD33bo'\n\ntrain_embeddings_per_sentence = '1-260zeDhoDdxQ3McfR7Hr4c6mfaLFBpa'\nval_embeddings_per_sentence = '1-2EN_l5NcdgJZ740Szt4g6RcIZ9GX_D2'\ntest_embeddings_per_sentence = '1gNKahNHussBAV-6mFyC66AxPTA0YhQAG'","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:33:52.962814Z","iopub.execute_input":"2023-08-12T18:33:52.965380Z","iopub.status.idle":"2023-08-12T18:33:52.972479Z","shell.execute_reply.started":"2023-08-12T18:33:52.965347Z","shell.execute_reply":"2023-08-12T18:33:52.970735Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!gdown {train}\n!gdown {val}\n!gdown {test}\n\n!gdown {train_embeddings_per_word}\n!gdown {val_embeddings_per_word}\n!gdown {test_embeddings_per_word}","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:33:52.975494Z","iopub.execute_input":"2023-08-12T18:33:52.976004Z","iopub.status.idle":"2023-08-12T18:34:43.396530Z","shell.execute_reply.started":"2023-08-12T18:33:52.975939Z","shell.execute_reply":"2023-08-12T18:34:43.394542Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1HqceFWkRXwEqgPcuAtACFVvHhKO_TGG6\nTo: /kaggle/working/train_final.pkl\n100%|███████████████████████████████████████| 3.47M/3.47M [00:00<00:00, 119MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1XEsLOUFJTnCGcitk4IUS23H6IlzCzwqZ\nTo: /kaggle/working/val_final.pkl\n100%|████████████████████████████████████████| 743k/743k [00:00<00:00, 90.8MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1Lu5ItQvj2iGRqMXJ-bovQkys0eilR9HZ\nTo: /kaggle/working/test_final.pkl\n100%|████████████████████████████████████████| 737k/737k [00:00<00:00, 86.0MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1-0Bb3pLy_EhEggA-VsOh8TIS92VbmmxV\nFrom (redirected): https://drive.google.com/uc?id=1-0Bb3pLy_EhEggA-VsOh8TIS92VbmmxV&confirm=t&uuid=bae17830-758a-426f-9be6-46ad0351c532\nTo: /kaggle/working/train_embeddings_per_word.pkl\n100%|██████████████████████████████████████| 1.08G/1.08G [00:18<00:00, 57.7MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1-0WpebJIz9q2PZ_Baf51ZUsiBx9pWVJP\nFrom (redirected): https://drive.google.com/uc?id=1-0WpebJIz9q2PZ_Baf51ZUsiBx9pWVJP&confirm=t&uuid=e530b58e-de63-4678-a99f-4d86a120ab35\nTo: /kaggle/working/val_embeddings_per_word.pkl\n100%|████████████████████████████████████████| 232M/232M [00:07<00:00, 30.2MB/s]\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1pi6DGhZ7AoGzC3cqP-ET5Qvkc3HD33bo\nFrom (redirected): https://drive.google.com/uc?id=1pi6DGhZ7AoGzC3cqP-ET5Qvkc3HD33bo&confirm=t&uuid=0a59ad59-2924-4a30-9a92-9e4322ee3564\nTo: /kaggle/working/test_embeddings_per_word.pkl\n100%|████████████████████████████████████████| 232M/232M [00:05<00:00, 42.0MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport string\nimport re\nimport pickle\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.isri import ISRIStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import confusion_matrix,accuracy_score, classification_report\nfrom sklearn.svm import SVC\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.layers import MaxPooling1D\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import backend as K\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom interpret_nlp.modules.lrp_modules import LRPLinear, LRPGRU\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing import sequence\nfrom collections import OrderedDict\nimport matplotlib.pyplot as plt\nfrom datasets import load_dataset\nfrom sklearn.preprocessing import OneHotEncoder\nimport keras_tuner","metadata":{"id":"cLmXB__I1uOg","execution":{"iopub.status.busy":"2023-08-12T18:34:43.409047Z","iopub.execute_input":"2023-08-12T18:34:43.409419Z","iopub.status.idle":"2023-08-12T18:34:56.025548Z","shell.execute_reply.started":"2023-08-12T18:34:43.409385Z","shell.execute_reply":"2023-08-12T18:34:56.024420Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:34:56.027400Z","iopub.execute_input":"2023-08-12T18:34:56.029191Z","iopub.status.idle":"2023-08-12T18:34:56.070648Z","shell.execute_reply.started":"2023-08-12T18:34:56.029142Z","shell.execute_reply":"2023-08-12T18:34:56.069428Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"label_to_class = {\n    0: 'none',\n    1: 'anger',\n    2: 'joy',\n    3: 'sadness',\n    4: 'love',\n    5: 'sympathy',\n    6: 'surprise',\n    7: 'fear'\n}\nclasses = ['none', 'anger', 'joy', 'sadness', 'love', 'sympathy', 'surprise', 'fear']","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:34:56.072973Z","iopub.execute_input":"2023-08-12T18:34:56.073658Z","iopub.status.idle":"2023-08-12T18:34:56.083855Z","shell.execute_reply.started":"2023-08-12T18:34:56.073621Z","shell.execute_reply":"2023-08-12T18:34:56.082805Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/train_final.pkl', 'rb') as f:\n    train = pickle.load(f)\n    \nwith open('/kaggle/working/val_final.pkl', 'rb') as f:\n    val = pickle.load(f)\n\nwith open('/kaggle/working/test_final.pkl', 'rb') as f:\n    test = pickle.load(f)\n\nwith open('/kaggle/working/train_embeddings_per_word.pkl', 'rb') as f:\n    train_embeddings = pickle.load(f)\n    \nwith open('/kaggle/working/val_embeddings_per_word.pkl', 'rb') as f:\n    val_embeddings = pickle.load(f)\n    \nwith open('/kaggle/working/test_embeddings_per_word.pkl', 'rb') as f:\n    test_embeddings = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:34:56.086989Z","iopub.execute_input":"2023-08-12T18:34:56.087599Z","iopub.status.idle":"2023-08-12T18:34:57.029338Z","shell.execute_reply.started":"2023-08-12T18:34:56.087562Z","shell.execute_reply":"2023-08-12T18:34:57.028215Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:34:57.031429Z","iopub.execute_input":"2023-08-12T18:34:57.033039Z","iopub.status.idle":"2023-08-12T18:34:57.057843Z","shell.execute_reply.started":"2023-08-12T18:34:57.032998Z","shell.execute_reply":"2023-08-12T18:34:57.056697Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                  tweet  label  \\\n5081  1996   يا مهند ياحبيبي انت تدور لبش مع اي احد ...      1   \n8264  حلب عفرين  اعتقال عشرات الشباب من قريه باسوطه ...      3   \n9777             انا نفسي مره اجرب اكون ليك حد اقرب : )      3   \n740   الصراحه احساس مخزي ونحن نكتفي بالتمثيل المشرف ...      3   \n6537  57   عاجل الايطالي فابيو باسل يفوز بدهب الاولي...      0   \n\n                                  tweet_with_out_emojis  \\\n5081  1996   يا مهند ياحبيبي انت تدور لبش مع اي احد ...   \n8264  حلب عفرين  اعتقال عشرات الشباب من قريه باسوطه ...   \n9777             انا نفسي مره اجرب اكون ليك حد اقرب : )   \n740   الصراحه احساس مخزي ونحن نكتفي بالتمثيل المشرف ...   \n6537  57   عاجل الايطالي فابيو باسل يفوز بدهب الاولي...   \n\n                                           cleaned_data  \\\n5081        مهند ياحبيبي تدور لبش متاكد ابو جاسم مايدري   \n8264  حلب عفرين اعتقال عشرات الشباب قريه باسوطه ريف ...   \n9777                             مره اجرب اكون ليك اقرب   \n740   الصراحه احساس مخزي نكتفي بالتمثيل المشرف الاول...   \n6537  عاجل الايطالي فابيو باسل يفوز بدهب الاوليمبياد...   \n\n                                          Root Stemming  \\\n5081                   هند حبب تدر لبش تكد ابو جسم ايدر   \n8264  حلب عفر عقل عشر شبب قره بسط ريف عفر قوت هرب عش...   \n9777                                مره جرب اكن ليك قرب   \n740           صرح حسس خزي كتف شرف اوليمبياد عوز صحه ريض   \n6537  عجل يطل ابو بسل يفز دهب اوليمبياد جودو بطل علم...   \n\n                                         Light Stemming  \n5081        مهند ياحبيبي تدور لبش متاكد ابو جاسم مايدري  \n8264  حلب عفر اعتقال عشر الشباب قريه باسوطه ريف عفر ...  \n9777                             مره اجرب اكون ليك اقرب  \n740   الصراحه احساس مخزي نكتفي بالتمثيل المشرف الاول...  \n6537  عاجل الايطالي فابيو باسل يفوز بدهب الاوليمبياد...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n      <th>tweet_with_out_emojis</th>\n      <th>cleaned_data</th>\n      <th>Root Stemming</th>\n      <th>Light Stemming</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5081</th>\n      <td>1996   يا مهند ياحبيبي انت تدور لبش مع اي احد ...</td>\n      <td>1</td>\n      <td>1996   يا مهند ياحبيبي انت تدور لبش مع اي احد ...</td>\n      <td>مهند ياحبيبي تدور لبش متاكد ابو جاسم مايدري</td>\n      <td>هند حبب تدر لبش تكد ابو جسم ايدر</td>\n      <td>مهند ياحبيبي تدور لبش متاكد ابو جاسم مايدري</td>\n    </tr>\n    <tr>\n      <th>8264</th>\n      <td>حلب عفرين  اعتقال عشرات الشباب من قريه باسوطه ...</td>\n      <td>3</td>\n      <td>حلب عفرين  اعتقال عشرات الشباب من قريه باسوطه ...</td>\n      <td>حلب عفرين اعتقال عشرات الشباب قريه باسوطه ريف ...</td>\n      <td>حلب عفر عقل عشر شبب قره بسط ريف عفر قوت هرب عش...</td>\n      <td>حلب عفر اعتقال عشر الشباب قريه باسوطه ريف عفر ...</td>\n    </tr>\n    <tr>\n      <th>9777</th>\n      <td>انا نفسي مره اجرب اكون ليك حد اقرب : )</td>\n      <td>3</td>\n      <td>انا نفسي مره اجرب اكون ليك حد اقرب : )</td>\n      <td>مره اجرب اكون ليك اقرب</td>\n      <td>مره جرب اكن ليك قرب</td>\n      <td>مره اجرب اكون ليك اقرب</td>\n    </tr>\n    <tr>\n      <th>740</th>\n      <td>الصراحه احساس مخزي ونحن نكتفي بالتمثيل المشرف ...</td>\n      <td>3</td>\n      <td>الصراحه احساس مخزي ونحن نكتفي بالتمثيل المشرف ...</td>\n      <td>الصراحه احساس مخزي نكتفي بالتمثيل المشرف الاول...</td>\n      <td>صرح حسس خزي كتف شرف اوليمبياد عوز صحه ريض</td>\n      <td>الصراحه احساس مخزي نكتفي بالتمثيل المشرف الاول...</td>\n    </tr>\n    <tr>\n      <th>6537</th>\n      <td>57   عاجل الايطالي فابيو باسل يفوز بدهب الاولي...</td>\n      <td>0</td>\n      <td>57   عاجل الايطالي فابيو باسل يفوز بدهب الاولي...</td>\n      <td>عاجل الايطالي فابيو باسل يفوز بدهب الاوليمبياد...</td>\n      <td>عجل يطل ابو بسل يفز دهب اوليمبياد جودو بطل علم...</td>\n      <td>عاجل الايطالي فابيو باسل يفوز بدهب الاوليمبياد...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train = train['Root Stemming']\ny_train = train['label']\nX_val = val['Root Stemming']\ny_val = val['label']\nX_test = test['Root Stemming']\ny_test = test['label']","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:34:57.059822Z","iopub.execute_input":"2023-08-12T18:34:57.060613Z","iopub.status.idle":"2023-08-12T18:34:57.067805Z","shell.execute_reply.started":"2023-08-12T18:34:57.060572Z","shell.execute_reply":"2023-08-12T18:34:57.066416Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"encoder = OneHotEncoder()\n\ny_train = encoder.fit_transform(train['label'].values.reshape(-1,1)).toarray()\ny_val = encoder.fit_transform(val['label'].values.reshape(-1,1)).toarray()\ny_test = encoder.transform(test['label'].values.reshape(-1,1)).toarray()","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:34:57.073218Z","iopub.execute_input":"2023-08-12T18:34:57.073611Z","iopub.status.idle":"2023-08-12T18:34:57.091546Z","shell.execute_reply.started":"2023-08-12T18:34:57.073580Z","shell.execute_reply":"2023-08-12T18:34:57.090475Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def prepare_tokenization(train, val, test=None, pad=500):\n  tokenizer = Tokenizer(oov_token='<UNK>')\n  tokenizer.fit_on_texts(train)\n  tokenizer.word_index['<PAD>'] = 0\n  train = tokenizer.texts_to_sequences(train)\n  val = tokenizer.texts_to_sequences(val)\n  if not pad==False:\n    train = sequence.pad_sequences(train, maxlen=pad)\n    val = sequence.pad_sequences(val, maxlen=pad)\n  if not type(test)==type(None):\n    test = tokenizer.texts_to_sequences(test)\n    if not pad==False:\n      test = sequence.pad_sequences(test, maxlen=pad)\n  v_size = len(tokenizer.word_index)\n  print(\"Vocabulary size={}\".format(v_size))\n  print(\"Number of Documents={}\".format(tokenizer.document_count))\n  if not type(test)==type(None):\n    return v_size, train, val, test\n  else:\n    return v_size, train, val","metadata":{"id":"bvPIxCa3UZI8","execution":{"iopub.status.busy":"2023-08-12T18:34:57.093047Z","iopub.execute_input":"2023-08-12T18:34:57.094140Z","iopub.status.idle":"2023-08-12T18:34:57.105010Z","shell.execute_reply.started":"2023-08-12T18:34:57.094099Z","shell.execute_reply":"2023-08-12T18:34:57.103055Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"VOCAB_SIZE, train_sequences, val_sequences, test_sequences = prepare_tokenization(X_train, X_val, X_test, pad=False)","metadata":{"id":"SvzRM2xtah_w","outputId":"94e8465f-4e8e-4065-b6b0-d0d6ce8678fd","execution":{"iopub.status.busy":"2023-08-12T18:34:57.106441Z","iopub.execute_input":"2023-08-12T18:34:57.108230Z","iopub.status.idle":"2023-08-12T18:34:57.458002Z","shell.execute_reply.started":"2023-08-12T18:34:57.108188Z","shell.execute_reply":"2023-08-12T18:34:57.455960Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Vocabulary size=8030\nNumber of Documents=7045\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ntrain_lens = [len(s) for s in train_sequences]\nplt.hist(train_lens)","metadata":{"id":"WV3GW9vPbshE","outputId":"8281e470-29b6-4dd0-89a0-43bb43dbf423","execution":{"iopub.status.busy":"2023-08-12T18:34:57.459568Z","iopub.execute_input":"2023-08-12T18:34:57.459938Z","iopub.status.idle":"2023-08-12T18:34:57.845729Z","shell.execute_reply.started":"2023-08-12T18:34:57.459909Z","shell.execute_reply":"2023-08-12T18:34:57.844684Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(array([6.830e+02, 1.919e+03, 1.858e+03, 1.304e+03, 1.098e+03, 1.730e+02,\n        8.000e+00, 0.000e+00, 1.000e+00, 1.000e+00]),\n array([ 0. ,  3.7,  7.4, 11.1, 14.8, 18.5, 22.2, 25.9, 29.6, 33.3, 37. ]),\n <BarContainer object of 10 artists>)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"max_length = 50","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:34:57.847650Z","iopub.execute_input":"2023-08-12T18:34:57.848125Z","iopub.status.idle":"2023-08-12T18:34:57.857990Z","shell.execute_reply.started":"2023-08-12T18:34:57.848085Z","shell.execute_reply":"2023-08-12T18:34:57.856434Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"max_length","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:34:57.859904Z","iopub.execute_input":"2023-08-12T18:34:57.860663Z","iopub.status.idle":"2023-08-12T18:34:57.872316Z","shell.execute_reply.started":"2023-08-12T18:34:57.860549Z","shell.execute_reply":"2023-08-12T18:34:57.871065Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"50"},"metadata":{}}]},{"cell_type":"code","source":"X_train = sequence.pad_sequences(train_sequences, maxlen=max_length)\nX_val = sequence.pad_sequences(val_sequences, maxlen=max_length)\nX_test = sequence.pad_sequences(test_sequences, maxlen=max_length)\nX_train.shape, X_val.shape, X_test.shape","metadata":{"id":"pK3W-LRfbyk1","outputId":"1a8b9134-0110-4907-ea00-5fa89741aadf","execution":{"iopub.status.busy":"2023-08-12T18:34:57.874125Z","iopub.execute_input":"2023-08-12T18:34:57.874643Z","iopub.status.idle":"2023-08-12T18:34:57.935482Z","shell.execute_reply.started":"2023-08-12T18:34:57.874595Z","shell.execute_reply":"2023-08-12T18:34:57.934351Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"((7045, 50), (1510, 50), (1510, 50))"},"metadata":{}}]},{"cell_type":"code","source":"BATCH_SIZE = 32\nEPOCHS = 50\nEMBED_SIZE = 768#86\nLEARNING_RATE =  0.0053516485623658835\n\nearly_stopping_monitor = tf.keras.callbacks.EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0,\n    patience=10,\n    verbose=0,\n    mode='max',\n    baseline=None,\n    restore_best_weights=True)","metadata":{"id":"aNV13COwKUd5","execution":{"iopub.status.busy":"2023-08-12T18:34:57.936798Z","iopub.execute_input":"2023-08-12T18:34:57.937259Z","iopub.status.idle":"2023-08-12T18:34:57.944499Z","shell.execute_reply.started":"2023-08-12T18:34:57.937223Z","shell.execute_reply":"2023-08-12T18:34:57.943364Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class myDataset(Dataset):\n  def __init__(self, train_sequences, labels):\n      # save data\n      self.train_sequences = train_sequences\n      self.labels = labels\n\n  def __getitem__(self, index):\n      # retrieve data\n      train_sequence = self.train_sequences[index]\n      label = self.labels[index]\n\n      return (torch.tensor(train_sequence).to(device), torch.tensor(label).to(device))\n\n  def __len__(self):\n      return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:34:57.946026Z","iopub.execute_input":"2023-08-12T18:34:57.947000Z","iopub.status.idle":"2023-08-12T18:34:57.956364Z","shell.execute_reply.started":"2023-08-12T18:34:57.946927Z","shell.execute_reply":"2023-08-12T18:34:57.955263Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_set = myDataset(X_train, y_train)\nval_set = myDataset(X_val, y_val)\ntest_set = myDataset(X_test, y_test)\n\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:34:57.959624Z","iopub.execute_input":"2023-08-12T18:34:57.960972Z","iopub.status.idle":"2023-08-12T18:34:57.968535Z","shell.execute_reply.started":"2023-08-12T18:34:57.960941Z","shell.execute_reply":"2023-08-12T18:34:57.967485Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from transformers import BertModel\n\nmodel = BertModel.from_pretrained(\"UBC-NLP/MARBERT\")\nembedding_matrix = model.embeddings.word_embeddings.weight\nVOCAB_SIZE_MARBERT = embedding_matrix.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:34:57.970048Z","iopub.execute_input":"2023-08-12T18:34:57.970648Z","iopub.status.idle":"2023-08-12T18:35:26.511516Z","shell.execute_reply.started":"2023-08-12T18:34:57.970589Z","shell.execute_reply":"2023-08-12T18:35:26.510445Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/701 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cae3eb49d8af4b0da52aa7c7790215fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0afa0ac09a540f78eb52ad1bfa72066"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"class GRU(nn.Module):\n    def __init__(self):\n        super(GRU, self).__init__()\n        self.embedding = nn.Embedding(VOCAB_SIZE_MARBERT, EMBED_SIZE)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix))\n        self.gru = nn.GRU(EMBED_SIZE, 256, num_layers=1)\n#         self.gru = LRPGRU(EMBED_SIZE, 256, num_layers=1)\n        self.dropout = nn.Dropout(0.011691195516528197)\n        self.fc = nn.Linear(256*50, 8)\n#         self.fc = LRPLinear(256, 8)\n        self.softmax = nn.Softmax(dim=0)\n    \n    def forward(self, x):\n        x = self.embedding(x)\n        h0 = torch.zeros(1, max_length, 256).to(device)\n        out, _ = self.gru(x, h0)\n        out = out.reshape(out.shape[0], -1)\n#         out = self.gru(x)[1][0]\n#         out = out.view(-1, 256)\n        x = self.dropout(out)\n        x = self.softmax(self.fc(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:35:26.513275Z","iopub.execute_input":"2023-08-12T18:35:26.513676Z","iopub.status.idle":"2023-08-12T18:35:26.524731Z","shell.execute_reply.started":"2023-08-12T18:35:26.513640Z","shell.execute_reply":"2023-08-12T18:35:26.523455Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = GRU().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n\nfor epoch in range(EPOCHS):\n    t_acc = 0\n    t_loss = 0\n    model.train()\n    for inputs, labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        t_acc += torch.sum(torch.argmax(outputs, axis=1)==torch.argmax(labels, axis=1)).detach().cpu().numpy()\n        t_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n    t_acc = t_acc/len(y_train)\n    t_loss = t_loss/len(y_train)\n    \n    v_acc = 0\n    v_loss = 0\n    model.eval()\n    for inputs, labels in val_loader:\n        outputs = model(inputs)\n        v_loss += criterion(outputs, labels).item()\n        v_acc += torch.sum(torch.argmax(outputs, axis=1)==torch.argmax(labels, axis=1)).detach().cpu().numpy()\n    v_acc = v_acc/len(y_val)\n    v_loss = v_loss/len(y_val)\n    # Print training progress\n    print(f'Epoch: {epoch+1}, Train loss: {t_loss:.4f}, Train accuracy: {t_acc:.4f}, Val loss: {v_loss:.4f}, Val accuracy: {v_acc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:35:26.526562Z","iopub.execute_input":"2023-08-12T18:35:26.527028Z","iopub.status.idle":"2023-08-12T18:39:13.446490Z","shell.execute_reply.started":"2023-08-12T18:35:26.526966Z","shell.execute_reply":"2023-08-12T18:39:13.445008Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_28/783509167.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix))\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Train loss: 0.0640, Train accuracy: 0.2392, Val loss: 0.0647, Val accuracy: 0.2748\nEpoch: 2, Train loss: 0.0632, Train accuracy: 0.2849, Val loss: 0.0649, Val accuracy: 0.2099\nEpoch: 3, Train loss: 0.0638, Train accuracy: 0.2525, Val loss: 0.0651, Val accuracy: 0.2086\nEpoch: 4, Train loss: 0.0633, Train accuracy: 0.2778, Val loss: 0.0643, Val accuracy: 0.2715\nEpoch: 5, Train loss: 0.0630, Train accuracy: 0.3009, Val loss: 0.0645, Val accuracy: 0.2775\nEpoch: 6, Train loss: 0.0628, Train accuracy: 0.3025, Val loss: 0.0644, Val accuracy: 0.2921\nEpoch: 7, Train loss: 0.0630, Train accuracy: 0.3042, Val loss: 0.0643, Val accuracy: 0.2742\nEpoch: 8, Train loss: 0.0629, Train accuracy: 0.2985, Val loss: 0.0643, Val accuracy: 0.2841\nEpoch: 9, Train loss: 0.0628, Train accuracy: 0.3011, Val loss: 0.0643, Val accuracy: 0.3040\nEpoch: 10, Train loss: 0.0628, Train accuracy: 0.3049, Val loss: 0.0644, Val accuracy: 0.2861\nEpoch: 11, Train loss: 0.0628, Train accuracy: 0.3107, Val loss: 0.0643, Val accuracy: 0.2788\nEpoch: 12, Train loss: 0.0627, Train accuracy: 0.3145, Val loss: 0.0644, Val accuracy: 0.3099\nEpoch: 13, Train loss: 0.0627, Train accuracy: 0.3229, Val loss: 0.0644, Val accuracy: 0.2795\nEpoch: 14, Train loss: 0.0627, Train accuracy: 0.3229, Val loss: 0.0643, Val accuracy: 0.2848\nEpoch: 15, Train loss: 0.0628, Train accuracy: 0.3080, Val loss: 0.0643, Val accuracy: 0.2887\nEpoch: 16, Train loss: 0.0626, Train accuracy: 0.3262, Val loss: 0.0643, Val accuracy: 0.2954\nEpoch: 17, Train loss: 0.0624, Train accuracy: 0.3168, Val loss: 0.0637, Val accuracy: 0.2894\nEpoch: 18, Train loss: 0.0625, Train accuracy: 0.3331, Val loss: 0.0642, Val accuracy: 0.2887\nEpoch: 19, Train loss: 0.0626, Train accuracy: 0.3143, Val loss: 0.0641, Val accuracy: 0.2914\nEpoch: 20, Train loss: 0.0624, Train accuracy: 0.3252, Val loss: 0.0642, Val accuracy: 0.2728\nEpoch: 21, Train loss: 0.0625, Train accuracy: 0.3252, Val loss: 0.0639, Val accuracy: 0.3053\nEpoch: 22, Train loss: 0.0623, Train accuracy: 0.3293, Val loss: 0.0642, Val accuracy: 0.3007\nEpoch: 23, Train loss: 0.0623, Train accuracy: 0.3296, Val loss: 0.0640, Val accuracy: 0.2934\nEpoch: 24, Train loss: 0.0622, Train accuracy: 0.3346, Val loss: 0.0639, Val accuracy: 0.2960\nEpoch: 25, Train loss: 0.0624, Train accuracy: 0.3320, Val loss: 0.0639, Val accuracy: 0.3007\nEpoch: 26, Train loss: 0.0623, Train accuracy: 0.3283, Val loss: 0.0639, Val accuracy: 0.3000\nEpoch: 27, Train loss: 0.0622, Train accuracy: 0.3347, Val loss: 0.0642, Val accuracy: 0.3026\nEpoch: 28, Train loss: 0.0621, Train accuracy: 0.3441, Val loss: 0.0639, Val accuracy: 0.3053\nEpoch: 29, Train loss: 0.0622, Train accuracy: 0.3480, Val loss: 0.0641, Val accuracy: 0.3033\nEpoch: 30, Train loss: 0.0623, Train accuracy: 0.3397, Val loss: 0.0640, Val accuracy: 0.3179\nEpoch: 31, Train loss: 0.0623, Train accuracy: 0.3429, Val loss: 0.0638, Val accuracy: 0.2868\nEpoch: 32, Train loss: 0.0624, Train accuracy: 0.3444, Val loss: 0.0641, Val accuracy: 0.2934\nEpoch: 33, Train loss: 0.0625, Train accuracy: 0.3402, Val loss: 0.0639, Val accuracy: 0.2980\nEpoch: 34, Train loss: 0.0622, Train accuracy: 0.3435, Val loss: 0.0640, Val accuracy: 0.2954\nEpoch: 35, Train loss: 0.0623, Train accuracy: 0.3422, Val loss: 0.0638, Val accuracy: 0.2947\nEpoch: 36, Train loss: 0.0622, Train accuracy: 0.3371, Val loss: 0.0637, Val accuracy: 0.3020\nEpoch: 37, Train loss: 0.0623, Train accuracy: 0.3404, Val loss: 0.0639, Val accuracy: 0.3126\nEpoch: 38, Train loss: 0.0623, Train accuracy: 0.3334, Val loss: 0.0639, Val accuracy: 0.2914\nEpoch: 39, Train loss: 0.0623, Train accuracy: 0.3392, Val loss: 0.0638, Val accuracy: 0.3119\nEpoch: 40, Train loss: 0.0622, Train accuracy: 0.3353, Val loss: 0.0641, Val accuracy: 0.2901\nEpoch: 41, Train loss: 0.0623, Train accuracy: 0.3344, Val loss: 0.0640, Val accuracy: 0.3046\nEpoch: 42, Train loss: 0.0623, Train accuracy: 0.3388, Val loss: 0.0640, Val accuracy: 0.2993\nEpoch: 43, Train loss: 0.0624, Train accuracy: 0.3330, Val loss: 0.0640, Val accuracy: 0.3053\nEpoch: 44, Train loss: 0.0622, Train accuracy: 0.3446, Val loss: 0.0639, Val accuracy: 0.2927\nEpoch: 45, Train loss: 0.0622, Train accuracy: 0.3394, Val loss: 0.0640, Val accuracy: 0.3086\nEpoch: 46, Train loss: 0.0623, Train accuracy: 0.3394, Val loss: 0.0636, Val accuracy: 0.3060\nEpoch: 47, Train loss: 0.0623, Train accuracy: 0.3340, Val loss: 0.0639, Val accuracy: 0.2921\nEpoch: 48, Train loss: 0.0623, Train accuracy: 0.3431, Val loss: 0.0642, Val accuracy: 0.2901\nEpoch: 49, Train loss: 0.0624, Train accuracy: 0.3322, Val loss: 0.0642, Val accuracy: 0.2868\nEpoch: 50, Train loss: 0.0622, Train accuracy: 0.3341, Val loss: 0.0642, Val accuracy: 0.2755\n","output_type":"stream"}]},{"cell_type":"code","source":"# predictions = model(torch.Tensor(X_test))\n\npredictions = []\nmodel.eval()\nfor inputs, labels in test_loader:\n    outputs = model(inputs)\n    predictions.extend(outputs.detach().cpu())\npredictions = np.vstack(predictions)\nprint(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=classes))","metadata":{"execution":{"iopub.status.busy":"2023-08-12T18:44:22.311675Z","iopub.execute_input":"2023-08-12T18:44:22.312175Z","iopub.status.idle":"2023-08-12T18:44:22.537662Z","shell.execute_reply.started":"2023-08-12T18:44:22.312134Z","shell.execute_reply":"2023-08-12T18:44:22.535221Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        none       0.14      0.10      0.11       229\n       anger       0.14      0.14      0.14       200\n         joy       0.15      0.10      0.12       205\n     sadness       0.15      0.21      0.17       185\n        love       0.14      0.12      0.13       193\n    sympathy       0.10      0.13      0.12       156\n    surprise       0.10      0.10      0.10       154\n        fear       0.08      0.10      0.09       188\n\n    accuracy                           0.12      1510\n   macro avg       0.12      0.12      0.12      1510\nweighted avg       0.13      0.12      0.12      1510\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}